{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krysten/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               processed_description salary_range  salary_bin\n",
      "0  hear care provid overview hearinglif nation he...     50k-100k           1\n",
      "1  cook descriptiontitl look great develop profes...        0-50k           0\n",
      "2  princip cloud secur architect remot summari ih...        150k+           3\n",
      "3  dishwash descriptiontitl 2,000 sign-on bonu gu...        0-50k           0\n",
      "4  insight analyst auto industri escal award-win ...     50k-100k           1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('processed_description.csv')\n",
    "#print(df.head())\n",
    "data = df[['processed_description','salary_range', 'salary_bin']]\n",
    "# target: salary_bin, convert to one hot encoding - list of binary (e.g: [1,0,0,0] for first bin) \n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confids\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.processed_description\n",
    "        self.targets = self.data.salary_bin\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (13350, 3)\n",
      "TRAIN Dataset: (10680, 3)\n",
      "TEST Dataset: (2670, 3)\n"
     ]
    }
   ],
   "source": [
    "# create dataset and dataloader\n",
    "train_size = 0.8\n",
    "train_dataset=data.sample(frac=train_size,random_state=200)\n",
    "test_dataset=data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with BERTClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 4)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.CrossEntropyLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids']\n",
    "        mask = data['mask']\n",
    "        token_type_ids = data['token_type_ids']\n",
    "        targets = data['targets']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        \n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "      \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/krysten/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  1.5398072004318237\n",
      "Epoch: 0, Loss:  1.4916586875915527\n",
      "Epoch: 0, Loss:  1.584442138671875\n",
      "Epoch: 0, Loss:  1.2940983772277832\n",
      "Epoch: 0, Loss:  1.47401762008667\n",
      "Epoch: 0, Loss:  1.3429944515228271\n",
      "Epoch: 0, Loss:  1.4043467044830322\n",
      "Epoch: 0, Loss:  1.3552888631820679\n",
      "Epoch: 0, Loss:  1.450002908706665\n",
      "Epoch: 0, Loss:  1.476799726486206\n",
      "Epoch: 0, Loss:  1.3114187717437744\n",
      "Epoch: 0, Loss:  1.4213018417358398\n",
      "Epoch: 0, Loss:  1.412161946296692\n",
      "Epoch: 0, Loss:  1.3066505193710327\n",
      "Epoch: 0, Loss:  1.3909187316894531\n",
      "Epoch: 0, Loss:  1.4036763906478882\n",
      "Epoch: 0, Loss:  1.3858307600021362\n",
      "Epoch: 0, Loss:  1.498443603515625\n",
      "Epoch: 0, Loss:  1.4933803081512451\n",
      "Epoch: 0, Loss:  1.35633385181427\n",
      "Epoch: 0, Loss:  1.395204782485962\n",
      "Epoch: 0, Loss:  1.268232822418213\n",
      "Epoch: 0, Loss:  1.231755256652832\n",
      "Epoch: 0, Loss:  1.2773098945617676\n",
      "Epoch: 0, Loss:  1.1674654483795166\n",
      "Epoch: 0, Loss:  1.1804039478302002\n",
      "Epoch: 0, Loss:  1.5212695598602295\n",
      "Epoch: 0, Loss:  1.4806256294250488\n",
      "Epoch: 0, Loss:  1.359820008277893\n",
      "Epoch: 0, Loss:  1.3586418628692627\n",
      "Epoch: 0, Loss:  1.1023403406143188\n",
      "Epoch: 0, Loss:  1.3571081161499023\n",
      "Epoch: 0, Loss:  1.4694610834121704\n",
      "Epoch: 0, Loss:  1.4339778423309326\n",
      "Epoch: 0, Loss:  1.262229323387146\n",
      "Epoch: 0, Loss:  1.2242388725280762\n",
      "Epoch: 0, Loss:  1.366760015487671\n",
      "Epoch: 0, Loss:  1.1982309818267822\n",
      "Epoch: 0, Loss:  1.2250421047210693\n",
      "Epoch: 0, Loss:  1.4659335613250732\n",
      "Epoch: 0, Loss:  1.4201529026031494\n",
      "Epoch: 0, Loss:  1.3835179805755615\n",
      "Epoch: 0, Loss:  1.380914568901062\n",
      "Epoch: 0, Loss:  1.2668882608413696\n",
      "Epoch: 0, Loss:  1.4786465167999268\n",
      "Epoch: 0, Loss:  1.3580243587493896\n",
      "Epoch: 0, Loss:  1.2856667041778564\n",
      "Epoch: 0, Loss:  1.4625928401947021\n",
      "Epoch: 0, Loss:  1.3726218938827515\n",
      "Epoch: 0, Loss:  1.2750592231750488\n",
      "Epoch: 0, Loss:  1.2451756000518799\n",
      "Epoch: 0, Loss:  1.4036952257156372\n",
      "Epoch: 0, Loss:  1.3891935348510742\n",
      "Epoch: 0, Loss:  1.398450493812561\n",
      "Epoch: 0, Loss:  1.4949589967727661\n",
      "Epoch: 0, Loss:  1.439775824546814\n",
      "Epoch: 0, Loss:  1.2548105716705322\n",
      "Epoch: 0, Loss:  1.5226540565490723\n",
      "Epoch: 0, Loss:  1.292771339416504\n",
      "Epoch: 0, Loss:  1.2087739706039429\n",
      "Epoch: 0, Loss:  1.3924973011016846\n",
      "Epoch: 0, Loss:  1.5566917657852173\n",
      "Epoch: 0, Loss:  1.2594387531280518\n",
      "Epoch: 0, Loss:  1.323835849761963\n",
      "Epoch: 0, Loss:  1.4604450464248657\n",
      "Epoch: 0, Loss:  1.4343340396881104\n",
      "Epoch: 0, Loss:  1.4397118091583252\n",
      "Epoch: 0, Loss:  1.468837022781372\n",
      "Epoch: 0, Loss:  1.3200435638427734\n",
      "Epoch: 0, Loss:  1.2504816055297852\n",
      "Epoch: 0, Loss:  1.444242238998413\n",
      "Epoch: 0, Loss:  1.2735977172851562\n",
      "Epoch: 0, Loss:  1.2631795406341553\n",
      "Epoch: 0, Loss:  1.2804028987884521\n",
      "Epoch: 0, Loss:  1.292518138885498\n",
      "Epoch: 0, Loss:  1.3332724571228027\n",
      "Epoch: 0, Loss:  1.163027286529541\n",
      "Epoch: 0, Loss:  1.4336258172988892\n",
      "Epoch: 0, Loss:  1.151078701019287\n",
      "Epoch: 0, Loss:  1.1409248113632202\n",
      "Epoch: 0, Loss:  1.6309157609939575\n",
      "Epoch: 0, Loss:  1.4253653287887573\n",
      "Epoch: 0, Loss:  1.2399826049804688\n",
      "Epoch: 0, Loss:  1.1354694366455078\n",
      "Epoch: 0, Loss:  1.3010571002960205\n",
      "Epoch: 0, Loss:  1.1185460090637207\n",
      "Epoch: 0, Loss:  1.1830265522003174\n",
      "Epoch: 0, Loss:  1.0886310338974\n",
      "Epoch: 0, Loss:  1.5166239738464355\n",
      "Epoch: 0, Loss:  1.2880147695541382\n",
      "Epoch: 0, Loss:  1.1946651935577393\n",
      "Epoch: 0, Loss:  1.737697720527649\n",
      "Epoch: 0, Loss:  1.1905465126037598\n",
      "Epoch: 0, Loss:  1.4742999076843262\n",
      "Epoch: 0, Loss:  1.419097661972046\n",
      "Epoch: 0, Loss:  1.1976460218429565\n",
      "Epoch: 0, Loss:  1.0107160806655884\n",
      "Epoch: 0, Loss:  1.1457123756408691\n",
      "Epoch: 0, Loss:  1.0921576023101807\n",
      "Epoch: 0, Loss:  1.2341047525405884\n",
      "Epoch: 0, Loss:  1.1377339363098145\n",
      "Epoch: 0, Loss:  1.1198745965957642\n",
      "Epoch: 0, Loss:  1.1453542709350586\n",
      "Epoch: 0, Loss:  1.8957722187042236\n",
      "Epoch: 0, Loss:  1.981020212173462\n",
      "Epoch: 0, Loss:  1.3234994411468506\n",
      "Epoch: 0, Loss:  1.5874584913253784\n",
      "Epoch: 0, Loss:  1.1157729625701904\n",
      "Epoch: 0, Loss:  1.0156298875808716\n",
      "Epoch: 0, Loss:  1.1454213857650757\n",
      "Epoch: 0, Loss:  1.4572802782058716\n",
      "Epoch: 0, Loss:  1.399254560470581\n",
      "Epoch: 0, Loss:  1.1635494232177734\n",
      "Epoch: 0, Loss:  1.2480895519256592\n",
      "Epoch: 0, Loss:  1.1185753345489502\n",
      "Epoch: 0, Loss:  1.4128283262252808\n",
      "Epoch: 0, Loss:  1.3392248153686523\n",
      "Epoch: 0, Loss:  1.2707314491271973\n",
      "Epoch: 0, Loss:  1.227616310119629\n",
      "Epoch: 0, Loss:  1.379155158996582\n",
      "Epoch: 0, Loss:  1.3160361051559448\n",
      "Epoch: 0, Loss:  1.2019672393798828\n",
      "Epoch: 0, Loss:  1.4781432151794434\n",
      "Epoch: 0, Loss:  1.5109028816223145\n",
      "Epoch: 0, Loss:  1.3847334384918213\n",
      "Epoch: 0, Loss:  1.399106502532959\n",
      "Epoch: 0, Loss:  1.4337743520736694\n",
      "Epoch: 0, Loss:  1.3079136610031128\n",
      "Epoch: 0, Loss:  1.405044436454773\n",
      "Epoch: 0, Loss:  1.1999731063842773\n",
      "Epoch: 0, Loss:  1.334867238998413\n",
      "Epoch: 0, Loss:  1.2299716472625732\n",
      "Epoch: 0, Loss:  1.1807743310928345\n",
      "Epoch: 0, Loss:  1.419979453086853\n",
      "Epoch: 0, Loss:  1.262387752532959\n",
      "Epoch: 0, Loss:  1.2689093351364136\n",
      "Epoch: 0, Loss:  1.347744107246399\n",
      "Epoch: 0, Loss:  1.4728705883026123\n",
      "Epoch: 0, Loss:  1.205327033996582\n",
      "Epoch: 0, Loss:  1.340494155883789\n",
      "Epoch: 0, Loss:  1.3191914558410645\n",
      "Epoch: 0, Loss:  1.3542048931121826\n",
      "Epoch: 0, Loss:  1.3400874137878418\n",
      "Epoch: 0, Loss:  1.3202714920043945\n",
      "Epoch: 0, Loss:  1.2652058601379395\n",
      "Epoch: 0, Loss:  1.2713385820388794\n",
      "Epoch: 0, Loss:  1.339746356010437\n",
      "Epoch: 0, Loss:  1.2886773347854614\n",
      "Epoch: 0, Loss:  1.553431749343872\n",
      "Epoch: 0, Loss:  1.331916332244873\n",
      "Epoch: 0, Loss:  1.4233009815216064\n",
      "Epoch: 0, Loss:  1.0433813333511353\n",
      "Epoch: 0, Loss:  1.2126213312149048\n",
      "Epoch: 0, Loss:  1.3243522644042969\n",
      "Epoch: 0, Loss:  1.1279373168945312\n",
      "Epoch: 0, Loss:  1.5708667039871216\n",
      "Epoch: 0, Loss:  1.448091983795166\n",
      "Epoch: 0, Loss:  1.2839813232421875\n",
      "Epoch: 0, Loss:  1.276800274848938\n",
      "Epoch: 0, Loss:  1.1603020429611206\n",
      "Epoch: 0, Loss:  1.376020908355713\n",
      "Epoch: 0, Loss:  1.2733490467071533\n",
      "Epoch: 0, Loss:  1.416387915611267\n",
      "Epoch: 0, Loss:  1.3180724382400513\n",
      "Epoch: 0, Loss:  1.4211207628250122\n",
      "Epoch: 0, Loss:  1.2696037292480469\n",
      "Epoch: 0, Loss:  1.207457423210144\n",
      "Epoch: 0, Loss:  1.4692952632904053\n",
      "Epoch: 0, Loss:  1.389024257659912\n",
      "Epoch: 0, Loss:  1.2153902053833008\n",
      "Epoch: 0, Loss:  1.2370975017547607\n",
      "Epoch: 0, Loss:  1.276747703552246\n",
      "Epoch: 0, Loss:  1.4017170667648315\n",
      "Epoch: 0, Loss:  1.3779631853103638\n",
      "Epoch: 0, Loss:  1.443926453590393\n",
      "Epoch: 0, Loss:  1.3141223192214966\n",
      "Epoch: 0, Loss:  1.1753582954406738\n",
      "Epoch: 0, Loss:  1.6049473285675049\n",
      "Epoch: 0, Loss:  1.2911791801452637\n",
      "Epoch: 0, Loss:  1.4166293144226074\n",
      "Epoch: 0, Loss:  1.0781126022338867\n",
      "Epoch: 0, Loss:  1.2979133129119873\n",
      "Epoch: 0, Loss:  1.093468427658081\n",
      "Epoch: 0, Loss:  1.2401291131973267\n",
      "Epoch: 0, Loss:  1.3689208030700684\n",
      "Epoch: 0, Loss:  1.4373984336853027\n",
      "Epoch: 0, Loss:  1.4906599521636963\n",
      "Epoch: 0, Loss:  1.1386432647705078\n",
      "Epoch: 0, Loss:  1.489901065826416\n",
      "Epoch: 0, Loss:  1.332153558731079\n",
      "Epoch: 0, Loss:  0.9988085031509399\n",
      "Epoch: 0, Loss:  1.2949199676513672\n",
      "Epoch: 0, Loss:  0.9695078134536743\n",
      "Epoch: 0, Loss:  1.4110076427459717\n",
      "Epoch: 0, Loss:  1.0360426902770996\n",
      "Epoch: 0, Loss:  1.188477635383606\n",
      "Epoch: 0, Loss:  1.0728315114974976\n",
      "Epoch: 0, Loss:  1.277957797050476\n",
      "Epoch: 0, Loss:  1.3189682960510254\n",
      "Epoch: 0, Loss:  1.2495882511138916\n",
      "Epoch: 0, Loss:  1.4876948595046997\n",
      "Epoch: 0, Loss:  1.2420654296875\n",
      "Epoch: 0, Loss:  1.2580839395523071\n",
      "Epoch: 0, Loss:  1.3423526287078857\n",
      "Epoch: 0, Loss:  1.1203792095184326\n",
      "Epoch: 0, Loss:  1.2373206615447998\n",
      "Epoch: 0, Loss:  0.9351540803909302\n",
      "Epoch: 0, Loss:  1.4747833013534546\n",
      "Epoch: 0, Loss:  1.0559953451156616\n",
      "Epoch: 0, Loss:  1.352997064590454\n",
      "Epoch: 0, Loss:  1.6064610481262207\n",
      "Epoch: 0, Loss:  1.1303539276123047\n",
      "Epoch: 0, Loss:  1.4198741912841797\n",
      "Epoch: 0, Loss:  1.2394256591796875\n",
      "Epoch: 0, Loss:  1.1629873514175415\n",
      "Epoch: 0, Loss:  1.3370171785354614\n",
      "Epoch: 0, Loss:  1.2401010990142822\n",
      "Epoch: 0, Loss:  1.2487390041351318\n",
      "Epoch: 0, Loss:  1.1392236948013306\n",
      "Epoch: 0, Loss:  1.2617802619934082\n",
      "Epoch: 0, Loss:  1.2946174144744873\n",
      "Epoch: 0, Loss:  1.1357672214508057\n",
      "Epoch: 0, Loss:  1.235228419303894\n",
      "Epoch: 0, Loss:  1.2368195056915283\n",
      "Epoch: 0, Loss:  1.26582932472229\n",
      "Epoch: 0, Loss:  1.1447410583496094\n",
      "Epoch: 0, Loss:  1.170541763305664\n",
      "Epoch: 0, Loss:  1.0925719738006592\n",
      "Epoch: 0, Loss:  1.2586603164672852\n",
      "Epoch: 0, Loss:  1.2431622743606567\n",
      "Epoch: 0, Loss:  1.1111464500427246\n",
      "Epoch: 0, Loss:  1.4161632061004639\n",
      "Epoch: 0, Loss:  1.1718496084213257\n",
      "Epoch: 0, Loss:  1.021065354347229\n",
      "Epoch: 0, Loss:  1.0459086894989014\n",
      "Epoch: 0, Loss:  1.342658519744873\n",
      "Epoch: 0, Loss:  1.190228819847107\n",
      "Epoch: 0, Loss:  1.1698155403137207\n",
      "Epoch: 0, Loss:  1.1556241512298584\n",
      "Epoch: 0, Loss:  1.3205375671386719\n",
      "Epoch: 0, Loss:  1.1150259971618652\n",
      "Epoch: 0, Loss:  1.1980973482131958\n",
      "Epoch: 0, Loss:  1.5975472927093506\n",
      "Epoch: 0, Loss:  1.0354986190795898\n",
      "Epoch: 0, Loss:  1.1237890720367432\n",
      "Epoch: 0, Loss:  0.8529664278030396\n",
      "Epoch: 0, Loss:  1.4067773818969727\n",
      "Epoch: 0, Loss:  0.9907788038253784\n",
      "Epoch: 0, Loss:  1.3287837505340576\n",
      "Epoch: 0, Loss:  0.9227323532104492\n",
      "Epoch: 0, Loss:  1.3858345746994019\n",
      "Epoch: 0, Loss:  1.3065463304519653\n",
      "Epoch: 0, Loss:  1.680527925491333\n",
      "Epoch: 0, Loss:  0.8748248815536499\n",
      "Epoch: 0, Loss:  0.9489902853965759\n",
      "Epoch: 0, Loss:  1.2045167684555054\n",
      "Epoch: 0, Loss:  0.8376895189285278\n",
      "Epoch: 0, Loss:  1.0924781560897827\n",
      "Epoch: 0, Loss:  1.029120683670044\n",
      "Epoch: 0, Loss:  1.3312724828720093\n",
      "Epoch: 0, Loss:  1.0580079555511475\n",
      "Epoch: 0, Loss:  1.4763731956481934\n",
      "Epoch: 0, Loss:  1.3515111207962036\n",
      "Epoch: 0, Loss:  1.0044796466827393\n",
      "Epoch: 0, Loss:  1.2238705158233643\n",
      "Epoch: 0, Loss:  1.346218228340149\n",
      "Epoch: 0, Loss:  1.416828989982605\n",
      "Epoch: 0, Loss:  1.312406063079834\n",
      "Epoch: 0, Loss:  1.147789478302002\n",
      "Epoch: 0, Loss:  1.1772632598876953\n",
      "Epoch: 0, Loss:  1.1280882358551025\n",
      "Epoch: 0, Loss:  1.1577956676483154\n",
      "Epoch: 0, Loss:  1.2971522808074951\n",
      "Epoch: 0, Loss:  1.3752464056015015\n",
      "Epoch: 0, Loss:  1.2025599479675293\n",
      "Epoch: 0, Loss:  1.1938273906707764\n",
      "Epoch: 0, Loss:  1.03754723072052\n",
      "Epoch: 0, Loss:  1.4218628406524658\n",
      "Epoch: 0, Loss:  1.1905715465545654\n",
      "Epoch: 0, Loss:  1.1782310009002686\n",
      "Epoch: 0, Loss:  0.9599390625953674\n",
      "Epoch: 0, Loss:  1.3608202934265137\n",
      "Epoch: 0, Loss:  1.075171709060669\n",
      "Epoch: 0, Loss:  1.1161439418792725\n",
      "Epoch: 0, Loss:  1.3095403909683228\n",
      "Epoch: 0, Loss:  0.9445911049842834\n",
      "Epoch: 0, Loss:  1.2485336065292358\n",
      "Epoch: 0, Loss:  1.348613977432251\n",
      "Epoch: 0, Loss:  0.8380560874938965\n",
      "Epoch: 0, Loss:  1.330294132232666\n",
      "Epoch: 0, Loss:  0.9789412021636963\n",
      "Epoch: 0, Loss:  1.1063982248306274\n",
      "Epoch: 0, Loss:  1.462921142578125\n",
      "Epoch: 0, Loss:  1.10444974899292\n",
      "Epoch: 0, Loss:  1.5786933898925781\n",
      "Epoch: 0, Loss:  1.1221728324890137\n",
      "Epoch: 0, Loss:  1.1698023080825806\n",
      "Epoch: 0, Loss:  1.27157461643219\n",
      "Epoch: 0, Loss:  1.297676682472229\n",
      "Epoch: 0, Loss:  1.0406279563903809\n",
      "Epoch: 0, Loss:  0.9926653504371643\n",
      "Epoch: 0, Loss:  0.9951095581054688\n",
      "Epoch: 0, Loss:  1.509486198425293\n",
      "Epoch: 0, Loss:  1.0829240083694458\n",
      "Epoch: 0, Loss:  1.1480145454406738\n",
      "Epoch: 0, Loss:  1.5528459548950195\n",
      "Epoch: 0, Loss:  1.2727597951889038\n",
      "Epoch: 0, Loss:  0.9774758815765381\n",
      "Epoch: 0, Loss:  1.1973446607589722\n",
      "Epoch: 0, Loss:  1.035895586013794\n",
      "Epoch: 0, Loss:  1.2360637187957764\n",
      "Epoch: 0, Loss:  1.0604325532913208\n",
      "Epoch: 0, Loss:  0.9460741877555847\n",
      "Epoch: 0, Loss:  1.0422536134719849\n",
      "Epoch: 0, Loss:  1.1764447689056396\n",
      "Epoch: 0, Loss:  0.899101972579956\n",
      "Epoch: 0, Loss:  1.039354920387268\n",
      "Epoch: 0, Loss:  1.5224800109863281\n",
      "Epoch: 0, Loss:  0.8998817801475525\n",
      "Epoch: 0, Loss:  1.2214183807373047\n",
      "Epoch: 0, Loss:  1.3999015092849731\n",
      "Epoch: 0, Loss:  1.0434110164642334\n",
      "Epoch: 0, Loss:  1.0461299419403076\n",
      "Epoch: 0, Loss:  1.2526192665100098\n",
      "Epoch: 0, Loss:  1.0897777080535889\n",
      "Epoch: 0, Loss:  1.1669080257415771\n",
      "Epoch: 0, Loss:  1.1397463083267212\n",
      "Epoch: 0, Loss:  1.1717936992645264\n",
      "Epoch: 0, Loss:  0.9840143918991089\n",
      "Epoch: 0, Loss:  1.0646562576293945\n",
      "Epoch: 0, Loss:  1.2261067628860474\n",
      "Epoch: 0, Loss:  1.2350659370422363\n",
      "Epoch: 0, Loss:  1.048581600189209\n",
      "Epoch: 0, Loss:  1.3646405935287476\n",
      "Epoch: 0, Loss:  1.06240975856781\n",
      "Epoch: 0, Loss:  1.5319712162017822\n",
      "Epoch: 0, Loss:  1.2894221544265747\n",
      "Epoch: 0, Loss:  1.4126782417297363\n",
      "Epoch: 0, Loss:  1.0324547290802002\n",
      "Epoch: 0, Loss:  1.390166163444519\n",
      "Epoch: 0, Loss:  1.1684778928756714\n",
      "Epoch: 0, Loss:  1.0811238288879395\n",
      "Epoch: 0, Loss:  0.9503227472305298\n",
      "Epoch: 0, Loss:  0.840221643447876\n",
      "Epoch: 0, Loss:  1.0226913690567017\n",
      "Epoch: 0, Loss:  1.003052830696106\n",
      "Epoch: 0, Loss:  1.322981834411621\n",
      "Epoch: 0, Loss:  1.2247326374053955\n",
      "Epoch: 0, Loss:  1.062020182609558\n",
      "Epoch: 0, Loss:  1.4484810829162598\n",
      "Epoch: 0, Loss:  0.9851593375205994\n",
      "Epoch: 0, Loss:  1.2802311182022095\n",
      "Epoch: 0, Loss:  0.8369789123535156\n",
      "Epoch: 0, Loss:  0.876736581325531\n",
      "Epoch: 0, Loss:  1.0797924995422363\n",
      "Epoch: 0, Loss:  0.8532898426055908\n",
      "Epoch: 0, Loss:  0.9165290594100952\n",
      "Epoch: 0, Loss:  1.1555938720703125\n",
      "Epoch: 0, Loss:  1.4869276285171509\n",
      "Epoch: 0, Loss:  1.3962633609771729\n",
      "Epoch: 0, Loss:  1.0715911388397217\n",
      "Epoch: 0, Loss:  0.9575556516647339\n",
      "Epoch: 0, Loss:  0.929365873336792\n",
      "Epoch: 0, Loss:  1.5708158016204834\n",
      "Epoch: 0, Loss:  1.0298621654510498\n",
      "Epoch: 0, Loss:  1.432204008102417\n",
      "Epoch: 0, Loss:  1.023025393486023\n",
      "Epoch: 0, Loss:  0.8227078914642334\n",
      "Epoch: 0, Loss:  0.9788753390312195\n",
      "Epoch: 0, Loss:  1.175108790397644\n",
      "Epoch: 0, Loss:  1.3128767013549805\n",
      "Epoch: 0, Loss:  0.8569779396057129\n",
      "Epoch: 0, Loss:  1.4218714237213135\n",
      "Epoch: 0, Loss:  1.3914552927017212\n",
      "Epoch: 0, Loss:  1.0761820077896118\n",
      "Epoch: 0, Loss:  1.107580542564392\n",
      "Epoch: 0, Loss:  1.020745038986206\n",
      "Epoch: 0, Loss:  1.331932544708252\n",
      "Epoch: 0, Loss:  0.7497031092643738\n",
      "Epoch: 0, Loss:  1.115944266319275\n",
      "Epoch: 0, Loss:  1.3678631782531738\n",
      "Epoch: 0, Loss:  1.193530797958374\n",
      "Epoch: 0, Loss:  0.8335736989974976\n",
      "Epoch: 0, Loss:  1.2988955974578857\n",
      "Epoch: 0, Loss:  1.1265220642089844\n",
      "Epoch: 0, Loss:  1.227028250694275\n",
      "Epoch: 0, Loss:  1.0232863426208496\n",
      "Epoch: 0, Loss:  1.1101551055908203\n",
      "Epoch: 0, Loss:  0.8630538582801819\n",
      "Epoch: 0, Loss:  1.0111947059631348\n",
      "Epoch: 0, Loss:  1.0443036556243896\n",
      "Epoch: 0, Loss:  0.819442629814148\n",
      "Epoch: 0, Loss:  0.9255061745643616\n",
      "Epoch: 0, Loss:  1.5532094240188599\n",
      "Epoch: 0, Loss:  1.1366920471191406\n",
      "Epoch: 0, Loss:  0.9926599264144897\n",
      "Epoch: 0, Loss:  0.8917357921600342\n",
      "Epoch: 0, Loss:  0.8762214183807373\n",
      "Epoch: 0, Loss:  1.2331581115722656\n",
      "Epoch: 0, Loss:  0.9414337873458862\n",
      "Epoch: 0, Loss:  1.1471989154815674\n",
      "Epoch: 0, Loss:  0.9870059490203857\n",
      "Epoch: 0, Loss:  0.7756824493408203\n",
      "Epoch: 0, Loss:  1.1949764490127563\n",
      "Epoch: 0, Loss:  1.0824674367904663\n",
      "Epoch: 0, Loss:  1.0967020988464355\n",
      "Epoch: 0, Loss:  0.9129812121391296\n",
      "Epoch: 0, Loss:  0.8626582622528076\n",
      "Epoch: 0, Loss:  0.8303217887878418\n",
      "Epoch: 0, Loss:  1.420338749885559\n",
      "Epoch: 0, Loss:  0.9037997722625732\n",
      "Epoch: 0, Loss:  1.2367632389068604\n",
      "Epoch: 0, Loss:  0.8883572816848755\n",
      "Epoch: 0, Loss:  1.027109146118164\n",
      "Epoch: 0, Loss:  1.2146536111831665\n",
      "Epoch: 0, Loss:  0.7696921825408936\n",
      "Epoch: 0, Loss:  0.8061550855636597\n",
      "Epoch: 0, Loss:  0.9286085367202759\n",
      "Epoch: 0, Loss:  1.4053993225097656\n",
      "Epoch: 0, Loss:  1.0374988317489624\n",
      "Epoch: 0, Loss:  0.8846656084060669\n",
      "Epoch: 0, Loss:  0.9393547177314758\n",
      "Epoch: 0, Loss:  1.431465744972229\n",
      "Epoch: 0, Loss:  0.7408111691474915\n",
      "Epoch: 0, Loss:  0.8828245401382446\n",
      "Epoch: 0, Loss:  1.292234182357788\n",
      "Epoch: 0, Loss:  0.8302456736564636\n",
      "Epoch: 0, Loss:  0.7721235752105713\n",
      "Epoch: 0, Loss:  1.2763360738754272\n",
      "Epoch: 0, Loss:  1.2186620235443115\n",
      "Epoch: 0, Loss:  0.9762672185897827\n",
      "Epoch: 0, Loss:  1.0653729438781738\n",
      "Epoch: 0, Loss:  0.7884605526924133\n",
      "Epoch: 0, Loss:  0.9425258636474609\n",
      "Epoch: 0, Loss:  1.2090345621109009\n",
      "Epoch: 0, Loss:  1.2879377603530884\n",
      "Epoch: 0, Loss:  0.8469602465629578\n",
      "Epoch: 0, Loss:  0.8315941095352173\n",
      "Epoch: 0, Loss:  1.0940697193145752\n",
      "Epoch: 0, Loss:  0.8826961517333984\n",
      "Epoch: 0, Loss:  0.8274946212768555\n",
      "Epoch: 0, Loss:  0.7783063650131226\n",
      "Epoch: 0, Loss:  1.385047197341919\n",
      "Epoch: 0, Loss:  1.2929788827896118\n",
      "Epoch: 0, Loss:  1.0882097482681274\n",
      "Epoch: 0, Loss:  0.5950331091880798\n",
      "Epoch: 0, Loss:  1.7531507015228271\n",
      "Epoch: 0, Loss:  0.8820577263832092\n",
      "Epoch: 0, Loss:  1.58353853225708\n",
      "Epoch: 0, Loss:  1.21476411819458\n",
      "Epoch: 0, Loss:  1.0399971008300781\n",
      "Epoch: 0, Loss:  1.2444149255752563\n",
      "Epoch: 0, Loss:  0.85737544298172\n",
      "Epoch: 0, Loss:  1.1417428255081177\n",
      "Epoch: 0, Loss:  1.1595308780670166\n",
      "Epoch: 0, Loss:  1.2811883687973022\n",
      "Epoch: 0, Loss:  0.8362506628036499\n",
      "Epoch: 0, Loss:  1.0480586290359497\n",
      "Epoch: 0, Loss:  1.3447275161743164\n",
      "Epoch: 0, Loss:  1.0957069396972656\n",
      "Epoch: 0, Loss:  0.8763253688812256\n",
      "Epoch: 0, Loss:  0.9494046568870544\n",
      "Epoch: 0, Loss:  1.0555386543273926\n",
      "Epoch: 0, Loss:  1.0603376626968384\n",
      "Epoch: 0, Loss:  1.2982704639434814\n",
      "Epoch: 0, Loss:  1.3589146137237549\n",
      "Epoch: 0, Loss:  1.0883514881134033\n",
      "Epoch: 0, Loss:  1.192609190940857\n",
      "Epoch: 0, Loss:  1.4639458656311035\n",
      "Epoch: 0, Loss:  1.1416081190109253\n",
      "Epoch: 0, Loss:  0.9053752422332764\n",
      "Epoch: 0, Loss:  0.976802408695221\n",
      "Epoch: 0, Loss:  1.1116448640823364\n",
      "Epoch: 0, Loss:  0.833936870098114\n",
      "Epoch: 0, Loss:  0.9449324011802673\n",
      "Epoch: 0, Loss:  1.0439088344573975\n",
      "Epoch: 0, Loss:  1.066307783126831\n",
      "Epoch: 0, Loss:  1.1683223247528076\n",
      "Epoch: 0, Loss:  1.699674129486084\n",
      "Epoch: 0, Loss:  0.86346435546875\n",
      "Epoch: 0, Loss:  0.8627594709396362\n",
      "Epoch: 0, Loss:  0.9662945866584778\n",
      "Epoch: 0, Loss:  1.30697762966156\n",
      "Epoch: 0, Loss:  0.8095808029174805\n",
      "Epoch: 0, Loss:  0.8678601980209351\n",
      "Epoch: 0, Loss:  1.053131103515625\n",
      "Epoch: 0, Loss:  0.9413440823554993\n",
      "Epoch: 0, Loss:  1.0666015148162842\n",
      "Epoch: 0, Loss:  1.257910966873169\n",
      "Epoch: 0, Loss:  1.2201731204986572\n",
      "Epoch: 0, Loss:  1.045539379119873\n",
      "Epoch: 0, Loss:  0.8663726449012756\n",
      "Epoch: 0, Loss:  0.9489554166793823\n",
      "Epoch: 0, Loss:  1.0336546897888184\n",
      "Epoch: 0, Loss:  0.9804523587226868\n",
      "Epoch: 0, Loss:  1.0653462409973145\n",
      "Epoch: 0, Loss:  0.9668278694152832\n",
      "Epoch: 0, Loss:  0.9650434255599976\n",
      "Epoch: 0, Loss:  1.0925650596618652\n",
      "Epoch: 0, Loss:  0.8246688842773438\n",
      "Epoch: 0, Loss:  1.1472203731536865\n",
      "Epoch: 0, Loss:  1.0081422328948975\n",
      "Epoch: 0, Loss:  0.863998532295227\n",
      "Epoch: 0, Loss:  0.866797149181366\n",
      "Epoch: 0, Loss:  0.832425594329834\n",
      "Epoch: 0, Loss:  0.8092032074928284\n",
      "Epoch: 0, Loss:  0.9388148784637451\n",
      "Epoch: 0, Loss:  0.9800173044204712\n",
      "Epoch: 0, Loss:  1.7172435522079468\n",
      "Epoch: 0, Loss:  0.7316329479217529\n",
      "Epoch: 0, Loss:  0.7237836718559265\n",
      "Epoch: 0, Loss:  0.7761171460151672\n",
      "Epoch: 0, Loss:  1.5212156772613525\n",
      "Epoch: 0, Loss:  1.1231377124786377\n",
      "Epoch: 0, Loss:  1.0793979167938232\n",
      "Epoch: 0, Loss:  0.6423813700675964\n",
      "Epoch: 0, Loss:  1.6855069398880005\n",
      "Epoch: 0, Loss:  1.0724693536758423\n",
      "Epoch: 0, Loss:  0.8185188174247742\n",
      "Epoch: 0, Loss:  0.9217909574508667\n",
      "Epoch: 0, Loss:  1.580306053161621\n",
      "Epoch: 0, Loss:  1.1487886905670166\n",
      "Epoch: 0, Loss:  1.648695707321167\n",
      "Epoch: 0, Loss:  1.1138079166412354\n",
      "Epoch: 0, Loss:  1.0718259811401367\n",
      "Epoch: 0, Loss:  1.2428685426712036\n",
      "Epoch: 0, Loss:  1.2450863122940063\n",
      "Epoch: 0, Loss:  1.1117191314697266\n",
      "Epoch: 0, Loss:  0.8265877962112427\n",
      "Epoch: 0, Loss:  0.9484697580337524\n",
      "Epoch: 0, Loss:  1.163631796836853\n",
      "Epoch: 0, Loss:  1.066715955734253\n",
      "Epoch: 0, Loss:  1.3573987483978271\n",
      "Epoch: 0, Loss:  1.222883701324463\n",
      "Epoch: 0, Loss:  1.2331656217575073\n",
      "Epoch: 0, Loss:  0.9507855772972107\n",
      "Epoch: 0, Loss:  1.229442834854126\n",
      "Epoch: 0, Loss:  1.0461972951889038\n",
      "Epoch: 0, Loss:  1.081173062324524\n",
      "Epoch: 0, Loss:  1.2969354391098022\n",
      "Epoch: 0, Loss:  0.8474547266960144\n",
      "Epoch: 0, Loss:  1.03922700881958\n",
      "Epoch: 0, Loss:  1.0960220098495483\n",
      "Epoch: 0, Loss:  0.9415035247802734\n",
      "Epoch: 0, Loss:  0.8588850498199463\n",
      "Epoch: 0, Loss:  0.928911030292511\n",
      "Epoch: 0, Loss:  0.8338654041290283\n",
      "Epoch: 0, Loss:  0.9189636707305908\n",
      "Epoch: 0, Loss:  1.0049370527267456\n",
      "Epoch: 0, Loss:  1.103975772857666\n",
      "Epoch: 0, Loss:  1.0182106494903564\n",
      "Epoch: 0, Loss:  0.792067289352417\n",
      "Epoch: 0, Loss:  0.9809188842773438\n",
      "Epoch: 0, Loss:  0.9094791412353516\n",
      "Epoch: 0, Loss:  0.9600685834884644\n",
      "Epoch: 0, Loss:  1.0635783672332764\n",
      "Epoch: 0, Loss:  1.1724954843521118\n",
      "Epoch: 0, Loss:  0.9788669347763062\n",
      "Epoch: 0, Loss:  0.9911911487579346\n",
      "Epoch: 0, Loss:  0.9073723554611206\n",
      "Epoch: 0, Loss:  0.771384596824646\n",
      "Epoch: 0, Loss:  1.0301727056503296\n",
      "Epoch: 0, Loss:  1.1465532779693604\n",
      "Epoch: 0, Loss:  0.7625973224639893\n",
      "Epoch: 0, Loss:  0.8260726928710938\n",
      "Epoch: 0, Loss:  1.0057296752929688\n",
      "Epoch: 0, Loss:  1.1743794679641724\n",
      "Epoch: 0, Loss:  0.8034809231758118\n",
      "Epoch: 0, Loss:  0.9287295341491699\n",
      "Epoch: 0, Loss:  1.378432035446167\n",
      "Epoch: 0, Loss:  1.1141458749771118\n",
      "Epoch: 0, Loss:  0.9968345165252686\n",
      "Epoch: 0, Loss:  0.5338780283927917\n",
      "Epoch: 0, Loss:  0.9789683818817139\n",
      "Epoch: 0, Loss:  0.6942052245140076\n",
      "Epoch: 0, Loss:  0.8327668905258179\n",
      "Epoch: 0, Loss:  0.5160298347473145\n",
      "Epoch: 0, Loss:  1.1863348484039307\n",
      "Epoch: 0, Loss:  1.286565899848938\n",
      "Epoch: 0, Loss:  1.00030517578125\n",
      "Epoch: 0, Loss:  0.9586197733879089\n",
      "Epoch: 0, Loss:  1.7578368186950684\n",
      "Epoch: 0, Loss:  0.9084611535072327\n",
      "Epoch: 0, Loss:  1.020696997642517\n",
      "Epoch: 0, Loss:  1.3956187963485718\n",
      "Epoch: 0, Loss:  1.119874358177185\n",
      "Epoch: 0, Loss:  1.3217536211013794\n",
      "Epoch: 0, Loss:  1.1720906496047974\n",
      "Epoch: 0, Loss:  1.2131500244140625\n",
      "Epoch: 0, Loss:  1.282010555267334\n",
      "Epoch: 0, Loss:  1.3399792909622192\n",
      "Epoch: 0, Loss:  0.6532633304595947\n",
      "Epoch: 0, Loss:  1.3017933368682861\n",
      "Epoch: 0, Loss:  0.9384709596633911\n",
      "Epoch: 0, Loss:  0.6676974296569824\n",
      "Epoch: 0, Loss:  0.9557104110717773\n",
      "Epoch: 0, Loss:  0.4486865997314453\n",
      "Epoch: 0, Loss:  1.4641878604888916\n",
      "Epoch: 0, Loss:  0.6663617491722107\n",
      "Epoch: 0, Loss:  0.8260180950164795\n",
      "Epoch: 0, Loss:  0.840172529220581\n",
      "Epoch: 0, Loss:  1.4254461526870728\n",
      "Epoch: 0, Loss:  0.9827863574028015\n",
      "Epoch: 0, Loss:  0.9213788509368896\n",
      "Epoch: 0, Loss:  0.9009098410606384\n",
      "Epoch: 0, Loss:  0.8749372959136963\n",
      "Epoch: 0, Loss:  0.954928457736969\n",
      "Epoch: 0, Loss:  0.742910623550415\n",
      "Epoch: 0, Loss:  1.219839096069336\n",
      "Epoch: 0, Loss:  0.8054324388504028\n",
      "Epoch: 0, Loss:  1.01645827293396\n",
      "Epoch: 0, Loss:  1.0623255968093872\n",
      "Epoch: 0, Loss:  1.179951548576355\n",
      "Epoch: 0, Loss:  1.2078553438186646\n",
      "Epoch: 0, Loss:  0.9424457550048828\n",
      "Epoch: 0, Loss:  1.0601423978805542\n",
      "Epoch: 0, Loss:  0.9893970489501953\n",
      "Epoch: 0, Loss:  0.6031350493431091\n",
      "Epoch: 0, Loss:  0.786195695400238\n",
      "Epoch: 0, Loss:  1.14128577709198\n",
      "Epoch: 0, Loss:  1.1872451305389404\n",
      "Epoch: 0, Loss:  1.445494532585144\n",
      "Epoch: 0, Loss:  1.4329054355621338\n",
      "Epoch: 0, Loss:  1.2330195903778076\n",
      "Epoch: 0, Loss:  1.0148978233337402\n",
      "Epoch: 0, Loss:  0.7211447954177856\n",
      "Epoch: 0, Loss:  0.8606452345848083\n",
      "Epoch: 0, Loss:  0.8245367407798767\n",
      "Epoch: 0, Loss:  0.9170166850090027\n",
      "Epoch: 0, Loss:  0.86097252368927\n",
      "Epoch: 0, Loss:  0.8809885382652283\n",
      "Epoch: 0, Loss:  0.736272931098938\n",
      "Epoch: 0, Loss:  1.0715893507003784\n",
      "Epoch: 0, Loss:  0.8791056275367737\n",
      "Epoch: 0, Loss:  1.180558443069458\n",
      "Epoch: 0, Loss:  1.1410884857177734\n",
      "Epoch: 0, Loss:  0.7574658393859863\n",
      "Epoch: 0, Loss:  1.0999040603637695\n",
      "Epoch: 0, Loss:  0.874077558517456\n",
      "Epoch: 0, Loss:  1.1946368217468262\n",
      "Epoch: 0, Loss:  1.1434166431427002\n",
      "Epoch: 0, Loss:  1.67832350730896\n",
      "Epoch: 0, Loss:  1.0715547800064087\n",
      "Epoch: 0, Loss:  0.9327620267868042\n",
      "Epoch: 0, Loss:  1.2172260284423828\n",
      "Epoch: 0, Loss:  0.8176612854003906\n",
      "Epoch: 0, Loss:  0.8339431285858154\n",
      "Epoch: 0, Loss:  1.0996760129928589\n",
      "Epoch: 0, Loss:  1.3343113660812378\n",
      "Epoch: 0, Loss:  1.407845139503479\n",
      "Epoch: 0, Loss:  1.2596290111541748\n",
      "Epoch: 0, Loss:  1.0519754886627197\n",
      "Epoch: 0, Loss:  1.3219637870788574\n",
      "Epoch: 0, Loss:  0.916522741317749\n",
      "Epoch: 0, Loss:  0.8964248895645142\n",
      "Epoch: 0, Loss:  0.9191193580627441\n",
      "Epoch: 0, Loss:  1.063611388206482\n",
      "Epoch: 0, Loss:  1.2165080308914185\n",
      "Epoch: 0, Loss:  1.002451777458191\n",
      "Epoch: 0, Loss:  0.6921839714050293\n",
      "Epoch: 0, Loss:  1.0392985343933105\n",
      "Epoch: 0, Loss:  0.8285130858421326\n",
      "Epoch: 0, Loss:  0.8413164019584656\n",
      "Epoch: 0, Loss:  0.9316750764846802\n",
      "Epoch: 0, Loss:  0.7342643141746521\n",
      "Epoch: 0, Loss:  1.0777543783187866\n",
      "Epoch: 0, Loss:  0.9056093692779541\n",
      "Epoch: 0, Loss:  0.8010560274124146\n",
      "Epoch: 0, Loss:  0.9805911183357239\n",
      "Epoch: 0, Loss:  0.7926278114318848\n",
      "Epoch: 0, Loss:  1.0489774942398071\n",
      "Epoch: 0, Loss:  0.6994948387145996\n",
      "Epoch: 0, Loss:  1.1640820503234863\n",
      "Epoch: 0, Loss:  0.8775667548179626\n",
      "Epoch: 0, Loss:  1.1779253482818604\n",
      "Epoch: 0, Loss:  1.1614007949829102\n",
      "Epoch: 0, Loss:  1.14274001121521\n",
      "Epoch: 0, Loss:  0.7855508327484131\n",
      "Epoch: 0, Loss:  0.752845048904419\n",
      "Epoch: 0, Loss:  1.438500165939331\n",
      "Epoch: 0, Loss:  0.9215535521507263\n",
      "Epoch: 0, Loss:  0.7355279922485352\n",
      "Epoch: 0, Loss:  1.1929734945297241\n",
      "Epoch: 0, Loss:  0.5606701374053955\n",
      "Epoch: 0, Loss:  0.9713790416717529\n",
      "Epoch: 0, Loss:  1.1809890270233154\n",
      "Epoch: 0, Loss:  0.7830557823181152\n",
      "Epoch: 0, Loss:  1.1484718322753906\n",
      "Epoch: 0, Loss:  0.9466382265090942\n",
      "Epoch: 0, Loss:  0.923349916934967\n",
      "Epoch: 0, Loss:  1.2177143096923828\n",
      "Epoch: 0, Loss:  0.7940397262573242\n",
      "Epoch: 0, Loss:  0.7077317237854004\n",
      "Epoch: 0, Loss:  1.0477068424224854\n",
      "Epoch: 0, Loss:  0.6866724491119385\n",
      "Epoch: 0, Loss:  1.0480207204818726\n",
      "Epoch: 0, Loss:  1.0938031673431396\n",
      "Epoch: 0, Loss:  0.9324161410331726\n",
      "Epoch: 0, Loss:  0.974000096321106\n",
      "Epoch: 0, Loss:  0.7211084961891174\n",
      "Epoch: 0, Loss:  0.7385398745536804\n",
      "Epoch: 0, Loss:  0.9404240846633911\n",
      "Epoch: 0, Loss:  1.022784948348999\n",
      "Epoch: 0, Loss:  1.1471043825149536\n",
      "Epoch: 0, Loss:  0.7855128049850464\n",
      "Epoch: 0, Loss:  0.8807161450386047\n",
      "Epoch: 0, Loss:  1.29866361618042\n",
      "Epoch: 0, Loss:  0.9835644364356995\n",
      "Epoch: 0, Loss:  1.142439842224121\n",
      "Epoch: 0, Loss:  1.113492727279663\n",
      "Epoch: 0, Loss:  0.7992153167724609\n",
      "Epoch: 0, Loss:  0.9442964196205139\n",
      "Epoch: 0, Loss:  1.3505620956420898\n",
      "Epoch: 0, Loss:  1.0225443840026855\n",
      "Epoch: 0, Loss:  0.9022836685180664\n",
      "Epoch: 0, Loss:  1.0285606384277344\n",
      "Epoch: 0, Loss:  0.8841155171394348\n",
      "Epoch: 0, Loss:  1.0314456224441528\n",
      "Epoch: 0, Loss:  0.9210968613624573\n",
      "Epoch: 0, Loss:  1.5005667209625244\n",
      "Epoch: 0, Loss:  0.7850462198257446\n",
      "Epoch: 0, Loss:  1.3253477811813354\n",
      "Epoch: 0, Loss:  1.032900094985962\n",
      "Epoch: 0, Loss:  0.9007548093795776\n",
      "Epoch: 0, Loss:  0.9683833122253418\n",
      "Epoch: 0, Loss:  1.3218497037887573\n",
      "Epoch: 0, Loss:  1.0386698246002197\n",
      "Epoch: 0, Loss:  0.9112458229064941\n",
      "Epoch: 0, Loss:  1.064388394355774\n",
      "Epoch: 0, Loss:  0.9994112253189087\n",
      "Epoch: 0, Loss:  0.6918790340423584\n",
      "Epoch: 0, Loss:  0.9899107217788696\n",
      "Epoch: 0, Loss:  0.6809502840042114\n",
      "Epoch: 0, Loss:  1.0807825326919556\n",
      "Epoch: 0, Loss:  0.9804056882858276\n",
      "Epoch: 0, Loss:  0.7904137372970581\n",
      "Epoch: 0, Loss:  0.6619444489479065\n",
      "Epoch: 0, Loss:  1.0130577087402344\n",
      "Epoch: 0, Loss:  1.310025930404663\n",
      "Epoch: 0, Loss:  1.1440105438232422\n",
      "Epoch: 0, Loss:  1.0050461292266846\n",
      "Epoch: 0, Loss:  0.7208425998687744\n",
      "Epoch: 0, Loss:  0.5636171102523804\n",
      "Epoch: 0, Loss:  1.0144429206848145\n",
      "Epoch: 0, Loss:  0.8084715604782104\n",
      "Epoch: 0, Loss:  0.7990987300872803\n",
      "Epoch: 0, Loss:  0.9946640133857727\n",
      "Epoch: 0, Loss:  1.0620789527893066\n",
      "Epoch: 0, Loss:  1.3238012790679932\n",
      "Epoch: 0, Loss:  0.6811704039573669\n",
      "Epoch: 0, Loss:  0.7921066284179688\n",
      "Epoch: 0, Loss:  0.9934703707695007\n",
      "Epoch: 0, Loss:  1.2318494319915771\n",
      "Epoch: 0, Loss:  0.688726544380188\n",
      "Epoch: 0, Loss:  1.2231998443603516\n",
      "Epoch: 0, Loss:  1.0474520921707153\n",
      "Epoch: 0, Loss:  1.0321998596191406\n",
      "Epoch: 0, Loss:  1.0006810426712036\n",
      "Epoch: 0, Loss:  1.05308997631073\n",
      "Epoch: 0, Loss:  0.5598174333572388\n",
      "Epoch: 0, Loss:  1.091291069984436\n",
      "Epoch: 0, Loss:  1.2572158575057983\n",
      "Epoch: 0, Loss:  1.2872952222824097\n",
      "Epoch: 0, Loss:  1.0055575370788574\n",
      "Epoch: 0, Loss:  0.9213963150978088\n",
      "Epoch: 0, Loss:  1.1616761684417725\n",
      "Epoch: 0, Loss:  1.1825497150421143\n",
      "Epoch: 0, Loss:  0.7772092819213867\n",
      "Epoch: 0, Loss:  1.1953233480453491\n",
      "Epoch: 0, Loss:  1.1267104148864746\n",
      "Epoch: 0, Loss:  1.0994975566864014\n",
      "Epoch: 0, Loss:  1.2565526962280273\n",
      "Epoch: 0, Loss:  1.0850841999053955\n",
      "Epoch: 0, Loss:  0.9016140699386597\n",
      "Epoch: 0, Loss:  1.1498059034347534\n",
      "Epoch: 0, Loss:  1.4006539583206177\n",
      "Epoch: 0, Loss:  1.0641902685165405\n",
      "Epoch: 0, Loss:  1.0565427541732788\n",
      "Epoch: 0, Loss:  0.7118199467658997\n",
      "Epoch: 0, Loss:  0.9024671912193298\n",
      "Epoch: 0, Loss:  0.9527233839035034\n",
      "Epoch: 0, Loss:  1.2038646936416626\n",
      "Epoch: 0, Loss:  0.7095649242401123\n",
      "Epoch: 0, Loss:  0.8802669048309326\n",
      "Epoch: 0, Loss:  0.9205400943756104\n",
      "Epoch: 0, Loss:  0.6862492561340332\n",
      "Epoch: 0, Loss:  1.6143522262573242\n",
      "Epoch: 0, Loss:  0.8090726137161255\n",
      "Epoch: 0, Loss:  1.1730856895446777\n",
      "Epoch: 0, Loss:  0.8121174573898315\n",
      "Epoch: 0, Loss:  1.304236888885498\n",
      "Epoch: 0, Loss:  0.7796916365623474\n",
      "Epoch: 0, Loss:  0.8938177824020386\n",
      "Epoch: 0, Loss:  0.8712620735168457\n",
      "Epoch: 0, Loss:  0.6367202401161194\n",
      "Epoch: 0, Loss:  0.9741204977035522\n",
      "Epoch: 0, Loss:  1.0037205219268799\n",
      "Epoch: 0, Loss:  0.9373346567153931\n",
      "Epoch: 0, Loss:  0.8943546414375305\n",
      "Epoch: 0, Loss:  1.4528069496154785\n",
      "Epoch: 0, Loss:  0.9544402956962585\n",
      "Epoch: 0, Loss:  0.8519411087036133\n",
      "Epoch: 0, Loss:  0.9294990301132202\n",
      "Epoch: 0, Loss:  1.3223944902420044\n",
      "Epoch: 0, Loss:  1.127814531326294\n",
      "Epoch: 0, Loss:  0.6263759136199951\n",
      "Epoch: 0, Loss:  1.2567275762557983\n",
      "Epoch: 0, Loss:  1.097278118133545\n",
      "Epoch: 0, Loss:  1.0471231937408447\n",
      "Epoch: 0, Loss:  0.8469365239143372\n",
      "Epoch: 0, Loss:  0.7601439356803894\n",
      "Epoch: 0, Loss:  0.6937717795372009\n",
      "Epoch: 0, Loss:  0.8953126072883606\n",
      "Epoch: 0, Loss:  1.0525693893432617\n",
      "Epoch: 0, Loss:  0.7237001061439514\n",
      "Epoch: 0, Loss:  0.6553698778152466\n",
      "Epoch: 0, Loss:  0.9440383315086365\n",
      "Epoch: 0, Loss:  0.5197544097900391\n",
      "Epoch: 0, Loss:  1.1051303148269653\n",
      "Epoch: 0, Loss:  0.9691823720932007\n",
      "Epoch: 0, Loss:  1.1131155490875244\n",
      "Epoch: 0, Loss:  0.5930687785148621\n",
      "Epoch: 0, Loss:  1.0389941930770874\n",
      "Epoch: 0, Loss:  1.3448327779769897\n",
      "Epoch: 0, Loss:  1.0512193441390991\n",
      "Epoch: 0, Loss:  0.8984137177467346\n",
      "Epoch: 0, Loss:  0.8897682428359985\n",
      "Epoch: 0, Loss:  0.9883636236190796\n",
      "Epoch: 0, Loss:  1.2539933919906616\n",
      "Epoch: 0, Loss:  0.9705977439880371\n",
      "Epoch: 0, Loss:  0.8664218187332153\n",
      "Epoch: 0, Loss:  0.4857642948627472\n",
      "Epoch: 0, Loss:  1.1091358661651611\n",
      "Epoch: 0, Loss:  0.6671584248542786\n",
      "Epoch: 0, Loss:  0.9968993067741394\n",
      "Epoch: 0, Loss:  0.8207961320877075\n",
      "Epoch: 0, Loss:  0.9031150341033936\n",
      "Epoch: 0, Loss:  0.8659958839416504\n",
      "Epoch: 0, Loss:  0.7590092420578003\n",
      "Epoch: 0, Loss:  0.6394206285476685\n",
      "Epoch: 0, Loss:  0.5851552486419678\n",
      "Epoch: 0, Loss:  1.0615118741989136\n",
      "Epoch: 0, Loss:  0.771327018737793\n",
      "Epoch: 0, Loss:  0.6842185258865356\n",
      "Epoch: 0, Loss:  0.8669115304946899\n",
      "Epoch: 0, Loss:  0.7380781769752502\n",
      "Epoch: 0, Loss:  0.5908636450767517\n",
      "Epoch: 0, Loss:  0.6188721060752869\n",
      "Epoch: 0, Loss:  0.6795134544372559\n",
      "Epoch: 0, Loss:  0.995138943195343\n",
      "Epoch: 0, Loss:  1.2330893278121948\n",
      "Epoch: 0, Loss:  0.9798361659049988\n",
      "Epoch: 0, Loss:  1.1422269344329834\n",
      "Epoch: 0, Loss:  0.9697962999343872\n",
      "Epoch: 0, Loss:  0.6907519102096558\n",
      "Epoch: 0, Loss:  1.0245951414108276\n",
      "Epoch: 0, Loss:  0.8640666007995605\n",
      "Epoch: 0, Loss:  1.2839856147766113\n",
      "Epoch: 0, Loss:  0.6933926939964294\n",
      "Epoch: 0, Loss:  1.0198354721069336\n",
      "Epoch: 0, Loss:  1.6757383346557617\n",
      "Epoch: 0, Loss:  0.7814873456954956\n",
      "Epoch: 0, Loss:  0.8464901447296143\n",
      "Epoch: 0, Loss:  0.7456475496292114\n",
      "Epoch: 0, Loss:  1.0909065008163452\n",
      "Epoch: 0, Loss:  1.1307162046432495\n",
      "Epoch: 0, Loss:  1.1455011367797852\n",
      "Epoch: 0, Loss:  0.6320592164993286\n",
      "Epoch: 0, Loss:  0.5333027243614197\n",
      "Epoch: 0, Loss:  0.9087565541267395\n",
      "Epoch: 0, Loss:  0.8567365407943726\n",
      "Epoch: 0, Loss:  0.7677633762359619\n",
      "Epoch: 0, Loss:  1.2680158615112305\n",
      "Epoch: 0, Loss:  0.642922580242157\n",
      "Epoch: 0, Loss:  1.4584324359893799\n",
      "Epoch: 0, Loss:  0.9628685712814331\n",
      "Epoch: 0, Loss:  1.2110997438430786\n",
      "Epoch: 0, Loss:  0.9503179788589478\n",
      "Epoch: 0, Loss:  1.4491779804229736\n",
      "Epoch: 0, Loss:  1.0226771831512451\n",
      "Epoch: 0, Loss:  0.7962297201156616\n",
      "Epoch: 0, Loss:  0.7827847599983215\n",
      "Epoch: 0, Loss:  0.5952043533325195\n",
      "Epoch: 0, Loss:  1.165412425994873\n",
      "Epoch: 0, Loss:  1.2849889993667603\n",
      "Epoch: 0, Loss:  0.8260879516601562\n",
      "Epoch: 0, Loss:  0.6075217723846436\n",
      "Epoch: 0, Loss:  0.5492682456970215\n",
      "Epoch: 0, Loss:  1.431809902191162\n",
      "Epoch: 0, Loss:  1.0013794898986816\n",
      "Epoch: 0, Loss:  1.0254021883010864\n",
      "Epoch: 0, Loss:  0.7981885075569153\n",
      "Epoch: 0, Loss:  1.2542359828948975\n",
      "Epoch: 0, Loss:  0.8673555850982666\n",
      "Epoch: 0, Loss:  0.9143170118331909\n",
      "Epoch: 0, Loss:  0.6952077150344849\n",
      "Epoch: 0, Loss:  0.9759299755096436\n",
      "Epoch: 0, Loss:  1.0151422023773193\n",
      "Epoch: 0, Loss:  0.8592162728309631\n",
      "Epoch: 0, Loss:  0.7796151638031006\n",
      "Epoch: 0, Loss:  0.9276491403579712\n",
      "Epoch: 0, Loss:  0.8894857168197632\n",
      "Epoch: 0, Loss:  1.096476674079895\n",
      "Epoch: 0, Loss:  0.8738129138946533\n",
      "Epoch: 0, Loss:  0.830305814743042\n",
      "Epoch: 0, Loss:  1.2551450729370117\n",
      "Epoch: 0, Loss:  0.4816288650035858\n",
      "Epoch: 0, Loss:  1.0315594673156738\n",
      "Epoch: 0, Loss:  0.8353506326675415\n",
      "Epoch: 0, Loss:  1.0412354469299316\n",
      "Epoch: 0, Loss:  0.5388426780700684\n",
      "Epoch: 0, Loss:  1.1799139976501465\n",
      "Epoch: 0, Loss:  1.7202332019805908\n",
      "Epoch: 0, Loss:  1.0915305614471436\n",
      "Epoch: 0, Loss:  0.688891589641571\n",
      "Epoch: 0, Loss:  0.7517767548561096\n",
      "Epoch: 0, Loss:  0.8871727585792542\n",
      "Epoch: 0, Loss:  1.1130445003509521\n",
      "Epoch: 0, Loss:  0.7585409283638\n",
      "Epoch: 0, Loss:  1.1710976362228394\n",
      "Epoch: 0, Loss:  0.864781379699707\n",
      "Epoch: 0, Loss:  1.110840916633606\n",
      "Epoch: 0, Loss:  1.2095184326171875\n",
      "Epoch: 0, Loss:  1.1571823358535767\n",
      "Epoch: 0, Loss:  0.8316999673843384\n",
      "Epoch: 0, Loss:  1.163751244544983\n",
      "Epoch: 0, Loss:  0.782996416091919\n",
      "Epoch: 0, Loss:  1.6382834911346436\n",
      "Epoch: 0, Loss:  1.046595811843872\n",
      "Epoch: 0, Loss:  0.9357044100761414\n",
      "Epoch: 0, Loss:  0.6314451098442078\n",
      "Epoch: 0, Loss:  0.8060189485549927\n",
      "Epoch: 0, Loss:  1.1172000169754028\n",
      "Epoch: 0, Loss:  1.1177268028259277\n",
      "Epoch: 0, Loss:  1.3104826211929321\n",
      "Epoch: 0, Loss:  0.7534859776496887\n",
      "Epoch: 0, Loss:  0.9878738522529602\n",
      "Epoch: 0, Loss:  0.7748249173164368\n",
      "Epoch: 0, Loss:  1.2407718896865845\n",
      "Epoch: 0, Loss:  0.4787754416465759\n",
      "Epoch: 0, Loss:  1.4582360982894897\n",
      "Epoch: 0, Loss:  0.889581561088562\n",
      "Epoch: 0, Loss:  1.0765559673309326\n",
      "Epoch: 0, Loss:  1.0756968259811401\n",
      "Epoch: 0, Loss:  0.9648857116699219\n",
      "Epoch: 0, Loss:  1.3217401504516602\n",
      "Epoch: 0, Loss:  1.0124304294586182\n",
      "Epoch: 0, Loss:  1.3193665742874146\n",
      "Epoch: 0, Loss:  1.5027716159820557\n",
      "Epoch: 0, Loss:  0.5793874859809875\n",
      "Epoch: 0, Loss:  0.8496568202972412\n",
      "Epoch: 0, Loss:  1.3015310764312744\n",
      "Epoch: 0, Loss:  0.9220793843269348\n",
      "Epoch: 0, Loss:  1.1943657398223877\n",
      "Epoch: 0, Loss:  1.162933111190796\n",
      "Epoch: 0, Loss:  0.4477430582046509\n",
      "Epoch: 0, Loss:  0.9736664295196533\n",
      "Epoch: 0, Loss:  0.6854501366615295\n",
      "Epoch: 0, Loss:  0.7289415001869202\n",
      "Epoch: 0, Loss:  1.3594762086868286\n",
      "Epoch: 0, Loss:  0.6947987675666809\n",
      "Epoch: 0, Loss:  0.6838856339454651\n",
      "Epoch: 0, Loss:  0.9371374845504761\n",
      "Epoch: 0, Loss:  1.0457795858383179\n",
      "Epoch: 0, Loss:  0.8805525302886963\n",
      "Epoch: 0, Loss:  0.9823848605155945\n",
      "Epoch: 0, Loss:  0.9466478228569031\n",
      "Epoch: 0, Loss:  0.7788465023040771\n",
      "Epoch: 0, Loss:  0.5556412935256958\n",
      "Epoch: 0, Loss:  0.645907998085022\n",
      "Epoch: 0, Loss:  0.8894791603088379\n",
      "Epoch: 0, Loss:  0.7924729585647583\n",
      "Epoch: 0, Loss:  0.9028055667877197\n",
      "Epoch: 0, Loss:  0.8092435598373413\n",
      "Epoch: 0, Loss:  1.1695911884307861\n",
      "Epoch: 0, Loss:  0.735386848449707\n",
      "Epoch: 0, Loss:  1.3464428186416626\n",
      "Epoch: 0, Loss:  0.7733359336853027\n",
      "Epoch: 0, Loss:  1.1742607355117798\n",
      "Epoch: 0, Loss:  0.9102248549461365\n",
      "Epoch: 0, Loss:  1.0106313228607178\n",
      "Epoch: 0, Loss:  0.945637583732605\n",
      "Epoch: 0, Loss:  1.0043582916259766\n",
      "Epoch: 0, Loss:  0.9828650951385498\n",
      "Epoch: 0, Loss:  0.8004723787307739\n",
      "Epoch: 0, Loss:  1.019624948501587\n",
      "Epoch: 0, Loss:  0.6435966491699219\n",
      "Epoch: 0, Loss:  0.9019167423248291\n",
      "Epoch: 0, Loss:  0.8703964948654175\n",
      "Epoch: 0, Loss:  1.0024749040603638\n",
      "Epoch: 0, Loss:  0.9617470502853394\n",
      "Epoch: 0, Loss:  0.9816653728485107\n",
      "Epoch: 0, Loss:  0.9189136028289795\n",
      "Epoch: 0, Loss:  1.5003912448883057\n",
      "Epoch: 0, Loss:  0.8168038129806519\n",
      "Epoch: 0, Loss:  0.8909979462623596\n",
      "Epoch: 0, Loss:  0.8290610313415527\n",
      "Epoch: 0, Loss:  1.440833330154419\n",
      "Epoch: 0, Loss:  1.0721707344055176\n",
      "Epoch: 0, Loss:  0.9130975008010864\n",
      "Epoch: 0, Loss:  0.9832063913345337\n",
      "Epoch: 0, Loss:  0.8065251708030701\n",
      "Epoch: 0, Loss:  1.1905591487884521\n",
      "Epoch: 0, Loss:  0.9658383131027222\n",
      "Epoch: 0, Loss:  0.7405210733413696\n",
      "Epoch: 0, Loss:  1.0473161935806274\n",
      "Epoch: 0, Loss:  0.8990668058395386\n",
      "Epoch: 0, Loss:  0.7264513373374939\n",
      "Epoch: 0, Loss:  0.8126038908958435\n",
      "Epoch: 0, Loss:  0.8382171988487244\n",
      "Epoch: 0, Loss:  0.8383291959762573\n",
      "Epoch: 0, Loss:  0.8025559186935425\n",
      "Epoch: 0, Loss:  0.9415180683135986\n",
      "Epoch: 0, Loss:  0.8909532427787781\n",
      "Epoch: 0, Loss:  0.9447770714759827\n",
      "Epoch: 0, Loss:  1.1160790920257568\n",
      "Epoch: 0, Loss:  0.7616145610809326\n",
      "Epoch: 0, Loss:  1.2729774713516235\n",
      "Epoch: 0, Loss:  1.4360567331314087\n",
      "Epoch: 0, Loss:  1.0505239963531494\n",
      "Epoch: 0, Loss:  0.9686094522476196\n",
      "Epoch: 0, Loss:  1.0325617790222168\n",
      "Epoch: 0, Loss:  1.041361927986145\n",
      "Epoch: 0, Loss:  1.2542731761932373\n",
      "Epoch: 0, Loss:  0.7061793804168701\n",
      "Epoch: 0, Loss:  0.4897306561470032\n",
      "Epoch: 0, Loss:  1.2737518548965454\n",
      "Epoch: 0, Loss:  0.831350564956665\n",
      "Epoch: 0, Loss:  0.5880357027053833\n",
      "Epoch: 0, Loss:  0.6577801704406738\n",
      "Epoch: 0, Loss:  0.7186084985733032\n",
      "Epoch: 0, Loss:  1.0598527193069458\n",
      "Epoch: 0, Loss:  1.0190361738204956\n",
      "Epoch: 0, Loss:  1.0596048831939697\n",
      "Epoch: 0, Loss:  0.6285853385925293\n",
      "Epoch: 0, Loss:  1.2518666982650757\n",
      "Epoch: 0, Loss:  0.5480948090553284\n",
      "Epoch: 0, Loss:  0.5321316123008728\n",
      "Epoch: 0, Loss:  1.5335536003112793\n",
      "Epoch: 0, Loss:  1.0299303531646729\n",
      "Epoch: 0, Loss:  0.6321726441383362\n",
      "Epoch: 0, Loss:  0.8065904378890991\n",
      "Epoch: 0, Loss:  0.6633620262145996\n",
      "Epoch: 0, Loss:  0.6731120347976685\n",
      "Epoch: 0, Loss:  1.3923909664154053\n",
      "Epoch: 0, Loss:  0.5456857085227966\n",
      "Epoch: 0, Loss:  1.1253467798233032\n",
      "Epoch: 0, Loss:  0.5590182542800903\n",
      "Epoch: 0, Loss:  0.8903030753135681\n",
      "Epoch: 0, Loss:  0.8418876528739929\n",
      "Epoch: 0, Loss:  0.6203086972236633\n",
      "Epoch: 0, Loss:  1.1881585121154785\n",
      "Epoch: 0, Loss:  0.6177525520324707\n",
      "Epoch: 0, Loss:  1.247286081314087\n",
      "Epoch: 0, Loss:  1.181634783744812\n",
      "Epoch: 0, Loss:  0.9845410585403442\n",
      "Epoch: 0, Loss:  0.7208712100982666\n",
      "Epoch: 0, Loss:  1.266616702079773\n",
      "Epoch: 0, Loss:  1.5536444187164307\n",
      "Epoch: 0, Loss:  1.4230692386627197\n",
      "Epoch: 0, Loss:  0.7013292908668518\n",
      "Epoch: 0, Loss:  0.6555600762367249\n",
      "Epoch: 0, Loss:  1.0554406642913818\n",
      "Epoch: 0, Loss:  0.9127407073974609\n",
      "Epoch: 0, Loss:  0.8812467455863953\n",
      "Epoch: 0, Loss:  1.5763386487960815\n",
      "Epoch: 0, Loss:  1.3052887916564941\n",
      "Epoch: 0, Loss:  0.7502325773239136\n",
      "Epoch: 0, Loss:  1.2000477313995361\n",
      "Epoch: 0, Loss:  0.6862908601760864\n",
      "Epoch: 0, Loss:  1.0327500104904175\n",
      "Epoch: 0, Loss:  1.137643575668335\n",
      "Epoch: 0, Loss:  0.9883325099945068\n",
      "Epoch: 0, Loss:  1.2986502647399902\n",
      "Epoch: 0, Loss:  0.5857369899749756\n",
      "Epoch: 0, Loss:  0.9381012916564941\n",
      "Epoch: 0, Loss:  0.5842025279998779\n",
      "Epoch: 0, Loss:  0.6331210136413574\n",
      "Epoch: 0, Loss:  0.9360707402229309\n",
      "Epoch: 0, Loss:  1.0406808853149414\n",
      "Epoch: 0, Loss:  0.9234980940818787\n",
      "Epoch: 0, Loss:  0.641701340675354\n",
      "Epoch: 0, Loss:  0.7397028207778931\n",
      "Epoch: 0, Loss:  0.6934636831283569\n",
      "Epoch: 0, Loss:  1.032970666885376\n",
      "Epoch: 0, Loss:  1.0168452262878418\n",
      "Epoch: 0, Loss:  0.5598946213722229\n",
      "Epoch: 0, Loss:  1.5898327827453613\n",
      "Epoch: 0, Loss:  0.9677720069885254\n",
      "Epoch: 0, Loss:  0.5634275674819946\n",
      "Epoch: 0, Loss:  1.0590721368789673\n",
      "Epoch: 0, Loss:  0.8103286027908325\n",
      "Epoch: 0, Loss:  0.7887543439865112\n",
      "Epoch: 0, Loss:  0.8667871952056885\n",
      "Epoch: 0, Loss:  0.8014467358589172\n",
      "Epoch: 0, Loss:  1.1790872812271118\n",
      "Epoch: 0, Loss:  0.5490899085998535\n",
      "Epoch: 0, Loss:  0.938917875289917\n",
      "Epoch: 0, Loss:  0.7723895907402039\n",
      "Epoch: 0, Loss:  0.5618200302124023\n",
      "Epoch: 0, Loss:  0.5513578653335571\n",
      "Epoch: 0, Loss:  0.9122745394706726\n",
      "Epoch: 0, Loss:  0.6969788074493408\n",
      "Epoch: 0, Loss:  1.0163147449493408\n",
      "Epoch: 0, Loss:  0.8797681331634521\n",
      "Epoch: 0, Loss:  0.8843069076538086\n",
      "Epoch: 0, Loss:  0.9731917381286621\n",
      "Epoch: 0, Loss:  1.0599621534347534\n",
      "Epoch: 0, Loss:  0.6376048922538757\n",
      "Epoch: 0, Loss:  1.6560945510864258\n",
      "Epoch: 0, Loss:  1.151644229888916\n",
      "Epoch: 0, Loss:  0.7951983213424683\n",
      "Epoch: 0, Loss:  0.6655033826828003\n",
      "Epoch: 0, Loss:  0.9251487255096436\n",
      "Epoch: 0, Loss:  1.562097191810608\n",
      "Epoch: 0, Loss:  0.6496866345405579\n",
      "Epoch: 0, Loss:  1.0288854837417603\n",
      "Epoch: 0, Loss:  0.9270510673522949\n",
      "Epoch: 0, Loss:  0.9049744009971619\n",
      "Epoch: 0, Loss:  0.9013929963111877\n",
      "Epoch: 0, Loss:  1.6218669414520264\n",
      "Epoch: 0, Loss:  0.7718365788459778\n",
      "Epoch: 0, Loss:  1.0452038049697876\n",
      "Epoch: 0, Loss:  0.4977610111236572\n",
      "Epoch: 0, Loss:  0.7991448640823364\n",
      "Epoch: 0, Loss:  0.7824047207832336\n",
      "Epoch: 0, Loss:  0.680045485496521\n",
      "Epoch: 0, Loss:  1.0441817045211792\n",
      "Epoch: 0, Loss:  0.7391525506973267\n",
      "Epoch: 0, Loss:  0.8779749274253845\n",
      "Epoch: 0, Loss:  0.7683961391448975\n",
      "Epoch: 0, Loss:  0.744632363319397\n",
      "Epoch: 0, Loss:  0.7991581559181213\n",
      "Epoch: 0, Loss:  1.2985138893127441\n",
      "Epoch: 0, Loss:  1.4726645946502686\n",
      "Epoch: 0, Loss:  0.5223202705383301\n",
      "Epoch: 0, Loss:  0.9121677875518799\n",
      "Epoch: 0, Loss:  0.8512896299362183\n",
      "Epoch: 0, Loss:  0.9178999662399292\n",
      "Epoch: 0, Loss:  1.0982210636138916\n",
      "Epoch: 0, Loss:  0.7113187313079834\n",
      "Epoch: 0, Loss:  0.5419859886169434\n",
      "Epoch: 0, Loss:  0.5724059343338013\n",
      "Epoch: 0, Loss:  0.8992734551429749\n",
      "Epoch: 0, Loss:  0.8491858243942261\n",
      "Epoch: 0, Loss:  0.7269749641418457\n",
      "Epoch: 0, Loss:  0.4845939874649048\n",
      "Epoch: 0, Loss:  0.7513156533241272\n",
      "Epoch: 0, Loss:  1.3377935886383057\n",
      "Epoch: 0, Loss:  1.0387980937957764\n",
      "Epoch: 0, Loss:  0.42807692289352417\n",
      "Epoch: 0, Loss:  1.281082034111023\n",
      "Epoch: 0, Loss:  0.7889637351036072\n",
      "Epoch: 0, Loss:  1.5161209106445312\n",
      "Epoch: 0, Loss:  0.9220021963119507\n",
      "Epoch: 0, Loss:  0.5107722878456116\n",
      "Epoch: 0, Loss:  1.0903383493423462\n",
      "Epoch: 0, Loss:  0.9369110465049744\n",
      "Epoch: 0, Loss:  0.9094734787940979\n",
      "Epoch: 0, Loss:  0.7354589104652405\n",
      "Epoch: 0, Loss:  1.162449598312378\n",
      "Epoch: 0, Loss:  1.5384608507156372\n",
      "Epoch: 0, Loss:  1.3599098920822144\n",
      "Epoch: 0, Loss:  0.8125512599945068\n",
      "Epoch: 0, Loss:  0.8042620420455933\n",
      "Epoch: 0, Loss:  0.6726241111755371\n",
      "Epoch: 0, Loss:  0.9405868053436279\n",
      "Epoch: 0, Loss:  1.0353271961212158\n",
      "Epoch: 0, Loss:  0.7168433666229248\n",
      "Epoch: 0, Loss:  0.8422796726226807\n",
      "Epoch: 0, Loss:  0.7875828146934509\n",
      "Epoch: 0, Loss:  0.8298065662384033\n",
      "Epoch: 0, Loss:  0.5133446455001831\n",
      "Epoch: 0, Loss:  0.8375305533409119\n",
      "Epoch: 0, Loss:  0.6761242151260376\n",
      "Epoch: 0, Loss:  1.2827163934707642\n",
      "Epoch: 0, Loss:  0.7485916614532471\n",
      "Epoch: 0, Loss:  1.1809806823730469\n",
      "Epoch: 0, Loss:  0.6862091422080994\n",
      "Epoch: 0, Loss:  1.5470197200775146\n",
      "Epoch: 0, Loss:  0.435300350189209\n",
      "Epoch: 0, Loss:  1.0491279363632202\n",
      "Epoch: 0, Loss:  0.8937365412712097\n",
      "Epoch: 0, Loss:  0.7027994990348816\n",
      "Epoch: 0, Loss:  0.5225141048431396\n",
      "Epoch: 0, Loss:  0.7620332837104797\n",
      "Epoch: 0, Loss:  1.1039197444915771\n",
      "Epoch: 0, Loss:  1.1162939071655273\n",
      "Epoch: 0, Loss:  0.9317528009414673\n",
      "Epoch: 0, Loss:  1.2634261846542358\n",
      "Epoch: 0, Loss:  1.0938572883605957\n",
      "Epoch: 0, Loss:  1.0773394107818604\n",
      "Epoch: 0, Loss:  1.032938838005066\n",
      "Epoch: 0, Loss:  0.4360707998275757\n",
      "Epoch: 0, Loss:  1.0405343770980835\n",
      "Epoch: 0, Loss:  1.3475677967071533\n",
      "Epoch: 0, Loss:  0.6141506433486938\n",
      "Epoch: 0, Loss:  0.8000906109809875\n",
      "Epoch: 0, Loss:  1.154567837715149\n",
      "Epoch: 0, Loss:  0.862334132194519\n",
      "Epoch: 0, Loss:  0.7700227499008179\n",
      "Epoch: 0, Loss:  1.1079936027526855\n",
      "Epoch: 0, Loss:  0.7392519116401672\n",
      "Epoch: 0, Loss:  0.972779393196106\n",
      "Epoch: 0, Loss:  0.9874130487442017\n",
      "Epoch: 0, Loss:  1.2889153957366943\n",
      "Epoch: 0, Loss:  1.3709849119186401\n",
      "Epoch: 0, Loss:  0.6047968864440918\n",
      "Epoch: 0, Loss:  0.8870677351951599\n",
      "Epoch: 0, Loss:  1.2129709720611572\n",
      "Epoch: 0, Loss:  0.807258129119873\n",
      "Epoch: 0, Loss:  0.8248098492622375\n",
      "Epoch: 0, Loss:  1.22739839553833\n",
      "Epoch: 0, Loss:  0.9378246068954468\n",
      "Epoch: 0, Loss:  1.195251703262329\n",
      "Epoch: 0, Loss:  0.8401309847831726\n",
      "Epoch: 0, Loss:  0.8954227566719055\n",
      "Epoch: 0, Loss:  0.6215437650680542\n",
      "Epoch: 0, Loss:  0.9521081447601318\n",
      "Epoch: 0, Loss:  0.96607905626297\n",
      "Epoch: 0, Loss:  0.9864498376846313\n",
      "Epoch: 0, Loss:  1.130231261253357\n",
      "Epoch: 0, Loss:  1.324007272720337\n",
      "Epoch: 0, Loss:  0.8675111532211304\n",
      "Epoch: 0, Loss:  1.0916324853897095\n",
      "Epoch: 0, Loss:  0.8460419178009033\n",
      "Epoch: 0, Loss:  0.8967373371124268\n",
      "Epoch: 0, Loss:  1.417092204093933\n",
      "Epoch: 0, Loss:  0.7884202003479004\n",
      "Epoch: 0, Loss:  1.0688925981521606\n",
      "Epoch: 0, Loss:  0.7675104141235352\n",
      "Epoch: 0, Loss:  0.8677096366882324\n",
      "Epoch: 0, Loss:  1.3203179836273193\n",
      "Epoch: 0, Loss:  0.8078187704086304\n",
      "Epoch: 0, Loss:  0.7078567743301392\n",
      "Epoch: 0, Loss:  0.8552656769752502\n",
      "Epoch: 0, Loss:  0.7068976163864136\n",
      "Epoch: 0, Loss:  1.078042984008789\n",
      "Epoch: 0, Loss:  1.201629400253296\n",
      "Epoch: 0, Loss:  0.9169734716415405\n",
      "Epoch: 0, Loss:  0.702815055847168\n",
      "Epoch: 0, Loss:  1.0120351314544678\n",
      "Epoch: 0, Loss:  1.0402395725250244\n",
      "Epoch: 0, Loss:  1.4032695293426514\n",
      "Epoch: 0, Loss:  0.8586344122886658\n",
      "Epoch: 0, Loss:  0.8835052847862244\n",
      "Epoch: 0, Loss:  1.1298284530639648\n",
      "Epoch: 0, Loss:  0.9657477140426636\n",
      "Epoch: 0, Loss:  1.2530797719955444\n",
      "Epoch: 0, Loss:  1.1991627216339111\n",
      "Epoch: 0, Loss:  0.7034231424331665\n",
      "Epoch: 0, Loss:  1.2390161752700806\n",
      "Epoch: 0, Loss:  0.6488521099090576\n",
      "Epoch: 0, Loss:  0.5808671712875366\n",
      "Epoch: 0, Loss:  1.2127349376678467\n",
      "Epoch: 0, Loss:  0.8368096351623535\n",
      "Epoch: 0, Loss:  0.9024041295051575\n",
      "Epoch: 0, Loss:  1.5714428424835205\n",
      "Epoch: 0, Loss:  0.9708818793296814\n",
      "Epoch: 0, Loss:  0.5936325788497925\n",
      "Epoch: 0, Loss:  1.144368290901184\n",
      "Epoch: 0, Loss:  0.6898617148399353\n",
      "Epoch: 0, Loss:  1.1508437395095825\n",
      "Epoch: 0, Loss:  0.8964635729789734\n",
      "Epoch: 0, Loss:  0.8508440256118774\n",
      "Epoch: 0, Loss:  0.9784702062606812\n",
      "Epoch: 0, Loss:  0.8831429481506348\n",
      "Epoch: 0, Loss:  0.7726706862449646\n",
      "Epoch: 0, Loss:  0.7390787601470947\n",
      "Epoch: 0, Loss:  0.7823817729949951\n",
      "Epoch: 0, Loss:  1.2327256202697754\n",
      "Epoch: 0, Loss:  0.629219651222229\n",
      "Epoch: 0, Loss:  1.0213556289672852\n",
      "Epoch: 0, Loss:  1.1038663387298584\n",
      "Epoch: 0, Loss:  0.620822012424469\n",
      "Epoch: 0, Loss:  0.6365711092948914\n",
      "Epoch: 0, Loss:  0.7528301477432251\n",
      "Epoch: 0, Loss:  1.058943748474121\n",
      "Epoch: 0, Loss:  0.8525175452232361\n",
      "Epoch: 0, Loss:  1.3441383838653564\n",
      "Epoch: 0, Loss:  0.5094632506370544\n",
      "Epoch: 0, Loss:  1.1802453994750977\n",
      "Epoch: 0, Loss:  1.2828518152236938\n",
      "Epoch: 0, Loss:  1.2754790782928467\n",
      "Epoch: 0, Loss:  0.72032630443573\n",
      "Epoch: 0, Loss:  1.4064538478851318\n",
      "Epoch: 0, Loss:  0.7521488070487976\n",
      "Epoch: 0, Loss:  1.0463284254074097\n",
      "Epoch: 0, Loss:  0.7731805443763733\n",
      "Epoch: 0, Loss:  0.9349254965782166\n",
      "Epoch: 0, Loss:  0.6552149653434753\n",
      "Epoch: 0, Loss:  0.770566999912262\n",
      "Epoch: 0, Loss:  1.257996678352356\n",
      "Epoch: 0, Loss:  0.6960420608520508\n",
      "Epoch: 0, Loss:  1.0728400945663452\n",
      "Epoch: 0, Loss:  0.9908722639083862\n",
      "Epoch: 0, Loss:  0.8363345265388489\n",
      "Epoch: 0, Loss:  1.2922203540802002\n",
      "Epoch: 0, Loss:  0.7009353637695312\n",
      "Epoch: 0, Loss:  0.6788100600242615\n",
      "Epoch: 0, Loss:  0.7006251811981201\n",
      "Epoch: 0, Loss:  0.7395973205566406\n",
      "Epoch: 0, Loss:  0.6111116409301758\n",
      "Epoch: 0, Loss:  1.1957987546920776\n",
      "Epoch: 0, Loss:  0.8055201768875122\n",
      "Epoch: 0, Loss:  0.7602803707122803\n",
      "Epoch: 0, Loss:  0.6942489147186279\n",
      "Epoch: 0, Loss:  1.0412598848342896\n",
      "Epoch: 0, Loss:  0.5918812155723572\n",
      "Epoch: 0, Loss:  1.4122804403305054\n",
      "Epoch: 0, Loss:  0.8675739169120789\n",
      "Epoch: 0, Loss:  0.8229472041130066\n",
      "Epoch: 0, Loss:  1.1493895053863525\n",
      "Epoch: 0, Loss:  1.2557507753372192\n",
      "Epoch: 0, Loss:  0.8502286672592163\n",
      "Epoch: 0, Loss:  1.172536849975586\n",
      "Epoch: 0, Loss:  0.9101938009262085\n",
      "Epoch: 0, Loss:  0.7523037791252136\n",
      "Epoch: 0, Loss:  0.7200093269348145\n",
      "Epoch: 0, Loss:  1.107869029045105\n",
      "Epoch: 0, Loss:  0.7028912305831909\n",
      "Epoch: 0, Loss:  0.8174846172332764\n",
      "Epoch: 0, Loss:  0.4783353805541992\n",
      "Epoch: 0, Loss:  0.8368310928344727\n",
      "Epoch: 0, Loss:  0.7915678024291992\n",
      "Epoch: 0, Loss:  1.1475032567977905\n",
      "Epoch: 0, Loss:  1.4268772602081299\n",
      "Epoch: 0, Loss:  0.8551026582717896\n",
      "Epoch: 0, Loss:  0.8534802794456482\n",
      "Epoch: 0, Loss:  0.7204481363296509\n",
      "Epoch: 0, Loss:  1.354902982711792\n",
      "Epoch: 0, Loss:  0.9932081699371338\n",
      "Epoch: 0, Loss:  1.4452826976776123\n",
      "Epoch: 0, Loss:  0.8752575516700745\n",
      "Epoch: 0, Loss:  1.077143907546997\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids']\n",
    "            mask = data['mask']\n",
    "            token_type_ids = data['token_type_ids']\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            \n",
    "    return fin_outputs, fin_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krysten/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6220973782771536\n",
      "F1 Score (Micro) = 0.6220973782771536\n",
      "F1 Score (Macro) = 0.6171781314585684\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    # output is the highest probability\n",
    "    outputs = np.argmax(outputs, axis=1)\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
