{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get embedding vectors - each row is a job posting, each column is a feature\n",
    "embeddings = pd.read_csv('text_embeddings.csv', index_col=0)\n",
    "\n",
    "all_postings = pd.read_csv('processed_description.csv', index_col=0)\n",
    "\n",
    "text = all_postings['processed_description']\n",
    "salary_bins = all_postings['salary_bin']\n",
    "salary_ranges = all_postings['salary_range']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train, validation, and test set: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, salary_bins, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5838951310861423\n",
      "F1: 0.5801127152649272\n",
      "AUROC: 0.8205238544057819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, C = 1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('AUROC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6209737827715356\n",
      "F1: 0.6108050157548137\n",
      "ROC AUC: 0.8449678741548263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6262172284644195\n",
      "F1: 0.6227912112059231\n",
      "ROC AUC: 0.8498956393466891\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb = xgb.XGBClassifier(objective='multi:softmax', num_class=5, max_depth=20, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601123595505618\n",
      "F1: 0.6018189006020477\n",
      "ROC AUC: 0.8058940526022109\n"
     ]
    }
   ],
   "source": [
    "#  feedforward\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,50) , max_iter=1000, learning_rate='adaptive', )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_layers=200):\n",
    "        super(NN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        for i in range(hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append((nn.ReLU()))\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "  \n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test loaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).float()\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).float()\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve\n",
    "from torch.nn import functional as F\n",
    "def train(epoch, model, optimizer, verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        # forward pass through the model\n",
    "        output = model(data)\n",
    "        # forward pass through the cross-entropy loss function\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # backward pass through the cross-entropy loss function and the model\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            losses.append(loss.detach())\n",
    "            if verbose :\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return losses\n",
    "\n",
    "def test(model, verbose=False):\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability      \n",
    "                                                                       \n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        accuracy_list.append(accuracy) \n",
    "        if verbose :\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                accuracy))\n",
    "    return test_loss\n",
    "        \n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/8544 (0%)]\tLoss: 1.390575\n",
      "Train Epoch: 0 [400/8544 (5%)]\tLoss: 1.324335\n",
      "Train Epoch: 0 [800/8544 (9%)]\tLoss: 1.270740\n",
      "Train Epoch: 0 [1200/8544 (14%)]\tLoss: 1.421902\n",
      "Train Epoch: 0 [1600/8544 (19%)]\tLoss: 1.198682\n",
      "Train Epoch: 0 [2000/8544 (23%)]\tLoss: 1.357615\n",
      "Train Epoch: 0 [2400/8544 (28%)]\tLoss: 1.323347\n",
      "Train Epoch: 0 [2800/8544 (33%)]\tLoss: 1.280538\n",
      "Train Epoch: 0 [3200/8544 (37%)]\tLoss: 1.232460\n",
      "Train Epoch: 0 [3600/8544 (42%)]\tLoss: 1.322284\n",
      "Train Epoch: 0 [4000/8544 (47%)]\tLoss: 1.186345\n",
      "Train Epoch: 0 [4400/8544 (51%)]\tLoss: 1.328351\n",
      "Train Epoch: 0 [4800/8544 (56%)]\tLoss: 1.384219\n",
      "Train Epoch: 0 [5200/8544 (61%)]\tLoss: 1.387678\n",
      "Train Epoch: 0 [5600/8544 (66%)]\tLoss: 1.417168\n",
      "Train Epoch: 0 [6000/8544 (70%)]\tLoss: 1.327852\n",
      "Train Epoch: 0 [6400/8544 (75%)]\tLoss: 1.246330\n",
      "Train Epoch: 0 [6800/8544 (80%)]\tLoss: 1.271080\n",
      "Train Epoch: 0 [7200/8544 (84%)]\tLoss: 1.423543\n",
      "Train Epoch: 0 [7600/8544 (89%)]\tLoss: 1.324338\n",
      "Train Epoch: 0 [8000/8544 (94%)]\tLoss: 1.368105\n",
      "Train Epoch: 0 [8400/8544 (98%)]\tLoss: 1.417475\n",
      "\n",
      "Test set: Average loss: 1.3317, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 1 [0/8544 (0%)]\tLoss: 1.406837\n",
      "Train Epoch: 1 [400/8544 (5%)]\tLoss: 1.280598\n",
      "Train Epoch: 1 [800/8544 (9%)]\tLoss: 1.577501\n",
      "Train Epoch: 1 [1200/8544 (14%)]\tLoss: 1.288430\n",
      "Train Epoch: 1 [1600/8544 (19%)]\tLoss: 1.282772\n",
      "Train Epoch: 1 [2000/8544 (23%)]\tLoss: 1.262250\n",
      "Train Epoch: 1 [2400/8544 (28%)]\tLoss: 1.346108\n",
      "Train Epoch: 1 [2800/8544 (33%)]\tLoss: 1.628567\n",
      "Train Epoch: 1 [3200/8544 (37%)]\tLoss: 1.421903\n",
      "Train Epoch: 1 [3600/8544 (42%)]\tLoss: 1.391702\n",
      "Train Epoch: 1 [4000/8544 (47%)]\tLoss: 1.198404\n",
      "Train Epoch: 1 [4400/8544 (51%)]\tLoss: 1.327016\n",
      "Train Epoch: 1 [4800/8544 (56%)]\tLoss: 1.402837\n",
      "Train Epoch: 1 [5200/8544 (61%)]\tLoss: 1.420779\n",
      "Train Epoch: 1 [5600/8544 (66%)]\tLoss: 1.251397\n",
      "Train Epoch: 1 [6000/8544 (70%)]\tLoss: 1.260577\n",
      "Train Epoch: 1 [6400/8544 (75%)]\tLoss: 1.263610\n",
      "Train Epoch: 1 [6800/8544 (80%)]\tLoss: 1.209543\n",
      "Train Epoch: 1 [7200/8544 (84%)]\tLoss: 1.252647\n",
      "Train Epoch: 1 [7600/8544 (89%)]\tLoss: 1.400687\n",
      "Train Epoch: 1 [8000/8544 (94%)]\tLoss: 1.381584\n",
      "Train Epoch: 1 [8400/8544 (98%)]\tLoss: 1.362107\n",
      "\n",
      "Test set: Average loss: 1.3297, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 2 [0/8544 (0%)]\tLoss: 1.429817\n",
      "Train Epoch: 2 [400/8544 (5%)]\tLoss: 1.329053\n",
      "Train Epoch: 2 [800/8544 (9%)]\tLoss: 1.310709\n",
      "Train Epoch: 2 [1200/8544 (14%)]\tLoss: 1.258379\n",
      "Train Epoch: 2 [1600/8544 (19%)]\tLoss: 1.441028\n",
      "Train Epoch: 2 [2000/8544 (23%)]\tLoss: 1.386090\n",
      "Train Epoch: 2 [2400/8544 (28%)]\tLoss: 1.290128\n",
      "Train Epoch: 2 [2800/8544 (33%)]\tLoss: 1.240415\n",
      "Train Epoch: 2 [3200/8544 (37%)]\tLoss: 1.459332\n",
      "Train Epoch: 2 [3600/8544 (42%)]\tLoss: 1.212328\n",
      "Train Epoch: 2 [4000/8544 (47%)]\tLoss: 1.269023\n",
      "Train Epoch: 2 [4400/8544 (51%)]\tLoss: 1.153850\n",
      "Train Epoch: 2 [4800/8544 (56%)]\tLoss: 1.358483\n",
      "Train Epoch: 2 [5200/8544 (61%)]\tLoss: 1.324522\n",
      "Train Epoch: 2 [5600/8544 (66%)]\tLoss: 1.357452\n",
      "Train Epoch: 2 [6000/8544 (70%)]\tLoss: 1.256987\n",
      "Train Epoch: 2 [6400/8544 (75%)]\tLoss: 1.371070\n",
      "Train Epoch: 2 [6800/8544 (80%)]\tLoss: 1.266845\n",
      "Train Epoch: 2 [7200/8544 (84%)]\tLoss: 1.377948\n",
      "Train Epoch: 2 [7600/8544 (89%)]\tLoss: 1.264786\n",
      "Train Epoch: 2 [8000/8544 (94%)]\tLoss: 1.146670\n",
      "Train Epoch: 2 [8400/8544 (98%)]\tLoss: 1.242386\n",
      "\n",
      "Test set: Average loss: 1.3305, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 3 [0/8544 (0%)]\tLoss: 1.064642\n",
      "Train Epoch: 3 [400/8544 (5%)]\tLoss: 1.397363\n",
      "Train Epoch: 3 [800/8544 (9%)]\tLoss: 1.425904\n",
      "Train Epoch: 3 [1200/8544 (14%)]\tLoss: 1.326181\n",
      "Train Epoch: 3 [1600/8544 (19%)]\tLoss: 1.247069\n",
      "Train Epoch: 3 [2000/8544 (23%)]\tLoss: 1.372447\n",
      "Train Epoch: 3 [2400/8544 (28%)]\tLoss: 1.350680\n",
      "Train Epoch: 3 [2800/8544 (33%)]\tLoss: 1.315673\n",
      "Train Epoch: 3 [3200/8544 (37%)]\tLoss: 1.371548\n",
      "Train Epoch: 3 [3600/8544 (42%)]\tLoss: 1.437467\n",
      "Train Epoch: 3 [4000/8544 (47%)]\tLoss: 1.279871\n",
      "Train Epoch: 3 [4400/8544 (51%)]\tLoss: 1.328320\n",
      "Train Epoch: 3 [4800/8544 (56%)]\tLoss: 1.334082\n",
      "Train Epoch: 3 [5200/8544 (61%)]\tLoss: 1.626163\n",
      "Train Epoch: 3 [5600/8544 (66%)]\tLoss: 1.624839\n",
      "Train Epoch: 3 [6000/8544 (70%)]\tLoss: 1.253436\n",
      "Train Epoch: 3 [6400/8544 (75%)]\tLoss: 1.239602\n",
      "Train Epoch: 3 [6800/8544 (80%)]\tLoss: 1.336341\n",
      "Train Epoch: 3 [7200/8544 (84%)]\tLoss: 1.158629\n",
      "Train Epoch: 3 [7600/8544 (89%)]\tLoss: 1.370540\n",
      "Train Epoch: 3 [8000/8544 (94%)]\tLoss: 1.273427\n",
      "Train Epoch: 3 [8400/8544 (98%)]\tLoss: 1.105900\n",
      "\n",
      "Test set: Average loss: 1.3352, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 4 [0/8544 (0%)]\tLoss: 1.294007\n",
      "Train Epoch: 4 [400/8544 (5%)]\tLoss: 1.284344\n",
      "Train Epoch: 4 [800/8544 (9%)]\tLoss: 1.240212\n",
      "Train Epoch: 4 [1200/8544 (14%)]\tLoss: 1.325013\n",
      "Train Epoch: 4 [1600/8544 (19%)]\tLoss: 1.295744\n",
      "Train Epoch: 4 [2000/8544 (23%)]\tLoss: 1.252384\n",
      "Train Epoch: 4 [2400/8544 (28%)]\tLoss: 1.301353\n",
      "Train Epoch: 4 [2800/8544 (33%)]\tLoss: 1.335543\n",
      "Train Epoch: 4 [3200/8544 (37%)]\tLoss: 1.352740\n",
      "Train Epoch: 4 [3600/8544 (42%)]\tLoss: 1.289561\n",
      "Train Epoch: 4 [4000/8544 (47%)]\tLoss: 1.214081\n",
      "Train Epoch: 4 [4400/8544 (51%)]\tLoss: 1.324222\n",
      "Train Epoch: 4 [4800/8544 (56%)]\tLoss: 1.435895\n",
      "Train Epoch: 4 [5200/8544 (61%)]\tLoss: 1.261695\n",
      "Train Epoch: 4 [5600/8544 (66%)]\tLoss: 1.220827\n",
      "Train Epoch: 4 [6000/8544 (70%)]\tLoss: 1.253761\n",
      "Train Epoch: 4 [6400/8544 (75%)]\tLoss: 1.359690\n",
      "Train Epoch: 4 [6800/8544 (80%)]\tLoss: 1.258355\n",
      "Train Epoch: 4 [7200/8544 (84%)]\tLoss: 1.256677\n",
      "Train Epoch: 4 [7600/8544 (89%)]\tLoss: 1.244117\n",
      "Train Epoch: 4 [8000/8544 (94%)]\tLoss: 1.294354\n",
      "Train Epoch: 4 [8400/8544 (98%)]\tLoss: 1.151205\n",
      "\n",
      "Test set: Average loss: 1.3301, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 5 [0/8544 (0%)]\tLoss: 1.369772\n",
      "Train Epoch: 5 [400/8544 (5%)]\tLoss: 1.268195\n",
      "Train Epoch: 5 [800/8544 (9%)]\tLoss: 1.325449\n",
      "Train Epoch: 5 [1200/8544 (14%)]\tLoss: 1.315711\n",
      "Train Epoch: 5 [1600/8544 (19%)]\tLoss: 1.163077\n",
      "Train Epoch: 5 [2000/8544 (23%)]\tLoss: 1.326295\n",
      "Train Epoch: 5 [2400/8544 (28%)]\tLoss: 1.327988\n",
      "Train Epoch: 5 [2800/8544 (33%)]\tLoss: 1.461052\n",
      "Train Epoch: 5 [3200/8544 (37%)]\tLoss: 1.172934\n",
      "Train Epoch: 5 [3600/8544 (42%)]\tLoss: 1.329852\n",
      "Train Epoch: 5 [4000/8544 (47%)]\tLoss: 1.421472\n",
      "Train Epoch: 5 [4400/8544 (51%)]\tLoss: 1.430065\n",
      "Train Epoch: 5 [4800/8544 (56%)]\tLoss: 1.318008\n",
      "Train Epoch: 5 [5200/8544 (61%)]\tLoss: 1.365955\n",
      "Train Epoch: 5 [5600/8544 (66%)]\tLoss: 1.254745\n",
      "Train Epoch: 5 [6000/8544 (70%)]\tLoss: 1.033926\n",
      "Train Epoch: 5 [6400/8544 (75%)]\tLoss: 1.309819\n",
      "Train Epoch: 5 [6800/8544 (80%)]\tLoss: 1.449034\n",
      "Train Epoch: 5 [7200/8544 (84%)]\tLoss: 1.221483\n",
      "Train Epoch: 5 [7600/8544 (89%)]\tLoss: 1.379270\n",
      "Train Epoch: 5 [8000/8544 (94%)]\tLoss: 1.547660\n",
      "Train Epoch: 5 [8400/8544 (98%)]\tLoss: 1.444298\n",
      "\n",
      "Test set: Average loss: 1.3300, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 6 [0/8544 (0%)]\tLoss: 1.425675\n",
      "Train Epoch: 6 [400/8544 (5%)]\tLoss: 1.183446\n",
      "Train Epoch: 6 [800/8544 (9%)]\tLoss: 1.313268\n",
      "Train Epoch: 6 [1200/8544 (14%)]\tLoss: 1.166181\n",
      "Train Epoch: 6 [1600/8544 (19%)]\tLoss: 1.250030\n",
      "Train Epoch: 6 [2000/8544 (23%)]\tLoss: 1.583989\n",
      "Train Epoch: 6 [2400/8544 (28%)]\tLoss: 1.514384\n",
      "Train Epoch: 6 [2800/8544 (33%)]\tLoss: 1.124757\n",
      "Train Epoch: 6 [3200/8544 (37%)]\tLoss: 1.347183\n",
      "Train Epoch: 6 [3600/8544 (42%)]\tLoss: 1.578681\n",
      "Train Epoch: 6 [4000/8544 (47%)]\tLoss: 1.424520\n",
      "Train Epoch: 6 [4400/8544 (51%)]\tLoss: 1.216974\n",
      "Train Epoch: 6 [4800/8544 (56%)]\tLoss: 1.427175\n",
      "Train Epoch: 6 [5200/8544 (61%)]\tLoss: 1.011431\n",
      "Train Epoch: 6 [5600/8544 (66%)]\tLoss: 1.256129\n",
      "Train Epoch: 6 [6000/8544 (70%)]\tLoss: 1.416908\n",
      "Train Epoch: 6 [6400/8544 (75%)]\tLoss: 1.286891\n",
      "Train Epoch: 6 [6800/8544 (80%)]\tLoss: 1.285807\n",
      "Train Epoch: 6 [7200/8544 (84%)]\tLoss: 1.327806\n",
      "Train Epoch: 6 [7600/8544 (89%)]\tLoss: 1.319584\n",
      "Train Epoch: 6 [8000/8544 (94%)]\tLoss: 1.217731\n",
      "Train Epoch: 6 [8400/8544 (98%)]\tLoss: 1.269694\n",
      "\n",
      "Test set: Average loss: 1.3294, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 7 [0/8544 (0%)]\tLoss: 1.379806\n",
      "Train Epoch: 7 [400/8544 (5%)]\tLoss: 1.203516\n",
      "Train Epoch: 7 [800/8544 (9%)]\tLoss: 1.315617\n",
      "Train Epoch: 7 [1200/8544 (14%)]\tLoss: 1.513407\n",
      "Train Epoch: 7 [1600/8544 (19%)]\tLoss: 1.261464\n",
      "Train Epoch: 7 [2000/8544 (23%)]\tLoss: 1.271524\n",
      "Train Epoch: 7 [2400/8544 (28%)]\tLoss: 1.396742\n",
      "Train Epoch: 7 [2800/8544 (33%)]\tLoss: 1.302723\n",
      "Train Epoch: 7 [3200/8544 (37%)]\tLoss: 1.408223\n",
      "Train Epoch: 7 [3600/8544 (42%)]\tLoss: 1.179466\n",
      "Train Epoch: 7 [4000/8544 (47%)]\tLoss: 1.408924\n",
      "Train Epoch: 7 [4400/8544 (51%)]\tLoss: 1.458903\n",
      "Train Epoch: 7 [4800/8544 (56%)]\tLoss: 1.485264\n",
      "Train Epoch: 7 [5200/8544 (61%)]\tLoss: 1.381928\n",
      "Train Epoch: 7 [5600/8544 (66%)]\tLoss: 1.447203\n",
      "Train Epoch: 7 [6000/8544 (70%)]\tLoss: 1.202582\n",
      "Train Epoch: 7 [6400/8544 (75%)]\tLoss: 1.338368\n",
      "Train Epoch: 7 [6800/8544 (80%)]\tLoss: 1.562866\n",
      "Train Epoch: 7 [7200/8544 (84%)]\tLoss: 1.455918\n",
      "Train Epoch: 7 [7600/8544 (89%)]\tLoss: 1.482077\n",
      "Train Epoch: 7 [8000/8544 (94%)]\tLoss: 1.544178\n",
      "Train Epoch: 7 [8400/8544 (98%)]\tLoss: 1.533862\n",
      "\n",
      "Test set: Average loss: 1.3299, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 8 [0/8544 (0%)]\tLoss: 1.325948\n",
      "Train Epoch: 8 [400/8544 (5%)]\tLoss: 1.505086\n",
      "Train Epoch: 8 [800/8544 (9%)]\tLoss: 1.307970\n",
      "Train Epoch: 8 [1200/8544 (14%)]\tLoss: 1.296814\n",
      "Train Epoch: 8 [1600/8544 (19%)]\tLoss: 1.265687\n",
      "Train Epoch: 8 [2000/8544 (23%)]\tLoss: 1.391416\n",
      "Train Epoch: 8 [2400/8544 (28%)]\tLoss: 1.366232\n",
      "Train Epoch: 8 [2800/8544 (33%)]\tLoss: 1.179032\n",
      "Train Epoch: 8 [3200/8544 (37%)]\tLoss: 1.408562\n",
      "Train Epoch: 8 [3600/8544 (42%)]\tLoss: 1.081508\n",
      "Train Epoch: 8 [4000/8544 (47%)]\tLoss: 1.459627\n",
      "Train Epoch: 8 [4400/8544 (51%)]\tLoss: 1.279927\n",
      "Train Epoch: 8 [4800/8544 (56%)]\tLoss: 1.340754\n",
      "Train Epoch: 8 [5200/8544 (61%)]\tLoss: 1.405315\n",
      "Train Epoch: 8 [5600/8544 (66%)]\tLoss: 1.307081\n",
      "Train Epoch: 8 [6000/8544 (70%)]\tLoss: 1.363843\n",
      "Train Epoch: 8 [6400/8544 (75%)]\tLoss: 1.328351\n",
      "Train Epoch: 8 [6800/8544 (80%)]\tLoss: 1.278503\n",
      "Train Epoch: 8 [7200/8544 (84%)]\tLoss: 1.229057\n",
      "Train Epoch: 8 [7600/8544 (89%)]\tLoss: 1.334309\n",
      "Train Epoch: 8 [8000/8544 (94%)]\tLoss: 1.399255\n",
      "Train Epoch: 8 [8400/8544 (98%)]\tLoss: 1.277391\n",
      "\n",
      "Test set: Average loss: 1.3294, Accuracy: 1019/2670 (38%)\n",
      "\n",
      "Train Epoch: 9 [0/8544 (0%)]\tLoss: 1.441242\n",
      "Train Epoch: 9 [400/8544 (5%)]\tLoss: 1.346842\n",
      "Train Epoch: 9 [800/8544 (9%)]\tLoss: 1.379351\n",
      "Train Epoch: 9 [1200/8544 (14%)]\tLoss: 1.215052\n",
      "Train Epoch: 9 [1600/8544 (19%)]\tLoss: 1.265124\n",
      "Train Epoch: 9 [2000/8544 (23%)]\tLoss: 1.263626\n",
      "Train Epoch: 9 [2400/8544 (28%)]\tLoss: 1.401219\n",
      "Train Epoch: 9 [2800/8544 (33%)]\tLoss: 1.421136\n",
      "Train Epoch: 9 [3200/8544 (37%)]\tLoss: 1.387267\n",
      "Train Epoch: 9 [3600/8544 (42%)]\tLoss: 1.213190\n",
      "Train Epoch: 9 [4000/8544 (47%)]\tLoss: 1.299959\n",
      "Train Epoch: 9 [4400/8544 (51%)]\tLoss: 1.441460\n",
      "Train Epoch: 9 [4800/8544 (56%)]\tLoss: 1.396774\n",
      "Train Epoch: 9 [5200/8544 (61%)]\tLoss: 1.386597\n",
      "Train Epoch: 9 [5600/8544 (66%)]\tLoss: 1.338717\n",
      "Train Epoch: 9 [6000/8544 (70%)]\tLoss: 1.343165\n",
      "Train Epoch: 9 [6400/8544 (75%)]\tLoss: 1.202102\n",
      "Train Epoch: 9 [6800/8544 (80%)]\tLoss: 1.380815\n",
      "Train Epoch: 9 [7200/8544 (84%)]\tLoss: 1.428191\n",
      "Train Epoch: 9 [7600/8544 (89%)]\tLoss: 1.325112\n",
      "Train Epoch: 9 [8000/8544 (94%)]\tLoss: 1.377075\n",
      "Train Epoch: 9 [8400/8544 (98%)]\tLoss: 1.339746\n",
      "\n",
      "Test set: Average loss: 1.3327, Accuracy: 1019/2670 (38%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "hidden_dim = 100\n",
    "\n",
    "hidden_layers = 25\n",
    "input_dim = embeddings.shape[1]\n",
    "output_dim = 4\n",
    "model = NN(input_dim, hidden_dim, output_dim, hidden_layers)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)    \n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch, model, optimizer, verbose=True)\n",
    "    test(model, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model (RNN Variant)\n",
    "Long Short-Term Memory layer in a neural netowrk model perform well in tasks involve learning long-term dependencies in sequential data, addressing limitation of a traditional RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/8544 (0%)]\tLoss: 1.365068\n",
      "Train Epoch: 0 [400/8544 (5%)]\tLoss: 1.218320\n",
      "Train Epoch: 0 [800/8544 (9%)]\tLoss: 1.382496\n",
      "Train Epoch: 0 [1200/8544 (14%)]\tLoss: 1.266356\n",
      "Train Epoch: 0 [1600/8544 (19%)]\tLoss: 1.323516\n",
      "Train Epoch: 0 [2000/8544 (23%)]\tLoss: 1.094645\n",
      "Train Epoch: 0 [2400/8544 (28%)]\tLoss: 1.125022\n",
      "Train Epoch: 0 [2800/8544 (33%)]\tLoss: 1.047598\n",
      "Train Epoch: 0 [3200/8544 (37%)]\tLoss: 0.928142\n",
      "Train Epoch: 0 [3600/8544 (42%)]\tLoss: 1.066682\n",
      "Train Epoch: 0 [4000/8544 (47%)]\tLoss: 1.091552\n",
      "Train Epoch: 0 [4400/8544 (51%)]\tLoss: 1.142164\n",
      "Train Epoch: 0 [4800/8544 (56%)]\tLoss: 1.119511\n",
      "Train Epoch: 0 [5200/8544 (61%)]\tLoss: 1.285020\n",
      "Train Epoch: 0 [5600/8544 (66%)]\tLoss: 1.333022\n",
      "Train Epoch: 0 [6000/8544 (70%)]\tLoss: 0.940334\n",
      "Train Epoch: 0 [6400/8544 (75%)]\tLoss: 1.381786\n",
      "Train Epoch: 0 [6800/8544 (80%)]\tLoss: 0.955437\n",
      "Train Epoch: 0 [7200/8544 (84%)]\tLoss: 0.888966\n",
      "Train Epoch: 0 [7600/8544 (89%)]\tLoss: 0.797990\n",
      "Train Epoch: 0 [8000/8544 (94%)]\tLoss: 1.125930\n",
      "Train Epoch: 0 [8400/8544 (98%)]\tLoss: 1.222408\n",
      "\n",
      "Test set: Average loss: 1.0279, Accuracy: 1393/2670 (52%)\n",
      "\n",
      "Train Epoch: 1 [0/8544 (0%)]\tLoss: 0.970836\n",
      "Train Epoch: 1 [400/8544 (5%)]\tLoss: 0.947527\n",
      "Train Epoch: 1 [800/8544 (9%)]\tLoss: 1.301787\n",
      "Train Epoch: 1 [1200/8544 (14%)]\tLoss: 0.778557\n",
      "Train Epoch: 1 [1600/8544 (19%)]\tLoss: 1.195122\n",
      "Train Epoch: 1 [2000/8544 (23%)]\tLoss: 1.375087\n",
      "Train Epoch: 1 [2400/8544 (28%)]\tLoss: 0.961949\n",
      "Train Epoch: 1 [2800/8544 (33%)]\tLoss: 0.937742\n",
      "Train Epoch: 1 [3200/8544 (37%)]\tLoss: 0.881776\n",
      "Train Epoch: 1 [3600/8544 (42%)]\tLoss: 1.367892\n",
      "Train Epoch: 1 [4000/8544 (47%)]\tLoss: 0.885404\n",
      "Train Epoch: 1 [4400/8544 (51%)]\tLoss: 0.965720\n",
      "Train Epoch: 1 [4800/8544 (56%)]\tLoss: 0.982735\n",
      "Train Epoch: 1 [5200/8544 (61%)]\tLoss: 1.062263\n",
      "Train Epoch: 1 [5600/8544 (66%)]\tLoss: 0.636615\n",
      "Train Epoch: 1 [6000/8544 (70%)]\tLoss: 0.827119\n",
      "Train Epoch: 1 [6400/8544 (75%)]\tLoss: 1.415869\n",
      "Train Epoch: 1 [6800/8544 (80%)]\tLoss: 1.225260\n",
      "Train Epoch: 1 [7200/8544 (84%)]\tLoss: 1.279898\n",
      "Train Epoch: 1 [7600/8544 (89%)]\tLoss: 1.199481\n",
      "Train Epoch: 1 [8000/8544 (94%)]\tLoss: 0.879168\n",
      "Train Epoch: 1 [8400/8544 (98%)]\tLoss: 1.173051\n",
      "\n",
      "Test set: Average loss: 0.9725, Accuracy: 1492/2670 (56%)\n",
      "\n",
      "Train Epoch: 2 [0/8544 (0%)]\tLoss: 1.213615\n",
      "Train Epoch: 2 [400/8544 (5%)]\tLoss: 0.977872\n",
      "Train Epoch: 2 [800/8544 (9%)]\tLoss: 0.744302\n",
      "Train Epoch: 2 [1200/8544 (14%)]\tLoss: 0.689894\n",
      "Train Epoch: 2 [1600/8544 (19%)]\tLoss: 0.625500\n",
      "Train Epoch: 2 [2000/8544 (23%)]\tLoss: 0.844615\n",
      "Train Epoch: 2 [2400/8544 (28%)]\tLoss: 0.580986\n",
      "Train Epoch: 2 [2800/8544 (33%)]\tLoss: 0.807727\n",
      "Train Epoch: 2 [3200/8544 (37%)]\tLoss: 0.751572\n",
      "Train Epoch: 2 [3600/8544 (42%)]\tLoss: 1.124992\n",
      "Train Epoch: 2 [4000/8544 (47%)]\tLoss: 0.977917\n",
      "Train Epoch: 2 [4400/8544 (51%)]\tLoss: 0.808293\n",
      "Train Epoch: 2 [4800/8544 (56%)]\tLoss: 1.536023\n",
      "Train Epoch: 2 [5200/8544 (61%)]\tLoss: 1.231243\n",
      "Train Epoch: 2 [5600/8544 (66%)]\tLoss: 0.992273\n",
      "Train Epoch: 2 [6000/8544 (70%)]\tLoss: 0.827446\n",
      "Train Epoch: 2 [6400/8544 (75%)]\tLoss: 0.574139\n",
      "Train Epoch: 2 [6800/8544 (80%)]\tLoss: 1.082499\n",
      "Train Epoch: 2 [7200/8544 (84%)]\tLoss: 1.240697\n",
      "Train Epoch: 2 [7600/8544 (89%)]\tLoss: 0.739911\n",
      "Train Epoch: 2 [8000/8544 (94%)]\tLoss: 0.962023\n",
      "Train Epoch: 2 [8400/8544 (98%)]\tLoss: 1.092982\n",
      "\n",
      "Test set: Average loss: 0.9520, Accuracy: 1513/2670 (57%)\n",
      "\n",
      "Train Epoch: 3 [0/8544 (0%)]\tLoss: 0.853568\n",
      "Train Epoch: 3 [400/8544 (5%)]\tLoss: 1.068273\n",
      "Train Epoch: 3 [800/8544 (9%)]\tLoss: 0.757632\n",
      "Train Epoch: 3 [1200/8544 (14%)]\tLoss: 0.769332\n",
      "Train Epoch: 3 [1600/8544 (19%)]\tLoss: 0.807503\n",
      "Train Epoch: 3 [2000/8544 (23%)]\tLoss: 1.029004\n",
      "Train Epoch: 3 [2400/8544 (28%)]\tLoss: 0.784722\n",
      "Train Epoch: 3 [2800/8544 (33%)]\tLoss: 0.761696\n",
      "Train Epoch: 3 [3200/8544 (37%)]\tLoss: 0.872407\n",
      "Train Epoch: 3 [3600/8544 (42%)]\tLoss: 0.744333\n",
      "Train Epoch: 3 [4000/8544 (47%)]\tLoss: 0.742150\n",
      "Train Epoch: 3 [4400/8544 (51%)]\tLoss: 1.108450\n",
      "Train Epoch: 3 [4800/8544 (56%)]\tLoss: 1.069312\n",
      "Train Epoch: 3 [5200/8544 (61%)]\tLoss: 1.546691\n",
      "Train Epoch: 3 [5600/8544 (66%)]\tLoss: 0.832728\n",
      "Train Epoch: 3 [6000/8544 (70%)]\tLoss: 0.752117\n",
      "Train Epoch: 3 [6400/8544 (75%)]\tLoss: 0.652261\n",
      "Train Epoch: 3 [6800/8544 (80%)]\tLoss: 0.872272\n",
      "Train Epoch: 3 [7200/8544 (84%)]\tLoss: 1.284732\n",
      "Train Epoch: 3 [7600/8544 (89%)]\tLoss: 1.059908\n",
      "Train Epoch: 3 [8000/8544 (94%)]\tLoss: 1.224687\n",
      "Train Epoch: 3 [8400/8544 (98%)]\tLoss: 1.143029\n",
      "\n",
      "Test set: Average loss: 0.9401, Accuracy: 1529/2670 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/8544 (0%)]\tLoss: 1.064425\n",
      "Train Epoch: 4 [400/8544 (5%)]\tLoss: 0.771413\n",
      "Train Epoch: 4 [800/8544 (9%)]\tLoss: 1.191483\n",
      "Train Epoch: 4 [1200/8544 (14%)]\tLoss: 0.652362\n",
      "Train Epoch: 4 [1600/8544 (19%)]\tLoss: 1.064075\n",
      "Train Epoch: 4 [2000/8544 (23%)]\tLoss: 1.005738\n",
      "Train Epoch: 4 [2400/8544 (28%)]\tLoss: 0.775245\n",
      "Train Epoch: 4 [2800/8544 (33%)]\tLoss: 1.185837\n",
      "Train Epoch: 4 [3200/8544 (37%)]\tLoss: 1.067707\n",
      "Train Epoch: 4 [3600/8544 (42%)]\tLoss: 0.736987\n",
      "Train Epoch: 4 [4000/8544 (47%)]\tLoss: 1.106502\n",
      "Train Epoch: 4 [4400/8544 (51%)]\tLoss: 1.276608\n",
      "Train Epoch: 4 [4800/8544 (56%)]\tLoss: 0.811957\n",
      "Train Epoch: 4 [5200/8544 (61%)]\tLoss: 0.908423\n",
      "Train Epoch: 4 [5600/8544 (66%)]\tLoss: 1.007538\n",
      "Train Epoch: 4 [6000/8544 (70%)]\tLoss: 0.630440\n",
      "Train Epoch: 4 [6400/8544 (75%)]\tLoss: 1.179014\n",
      "Train Epoch: 4 [6800/8544 (80%)]\tLoss: 0.670497\n",
      "Train Epoch: 4 [7200/8544 (84%)]\tLoss: 1.217505\n",
      "Train Epoch: 4 [7600/8544 (89%)]\tLoss: 0.708992\n",
      "Train Epoch: 4 [8000/8544 (94%)]\tLoss: 0.666507\n",
      "Train Epoch: 4 [8400/8544 (98%)]\tLoss: 0.802355\n",
      "\n",
      "Test set: Average loss: 0.9339, Accuracy: 1570/2670 (59%)\n",
      "\n",
      "Train Epoch: 5 [0/8544 (0%)]\tLoss: 0.490923\n",
      "Train Epoch: 5 [400/8544 (5%)]\tLoss: 0.919353\n",
      "Train Epoch: 5 [800/8544 (9%)]\tLoss: 1.224059\n",
      "Train Epoch: 5 [1200/8544 (14%)]\tLoss: 0.767770\n",
      "Train Epoch: 5 [1600/8544 (19%)]\tLoss: 0.726855\n",
      "Train Epoch: 5 [2000/8544 (23%)]\tLoss: 1.001701\n",
      "Train Epoch: 5 [2400/8544 (28%)]\tLoss: 1.517214\n",
      "Train Epoch: 5 [2800/8544 (33%)]\tLoss: 1.001798\n",
      "Train Epoch: 5 [3200/8544 (37%)]\tLoss: 0.881481\n",
      "Train Epoch: 5 [3600/8544 (42%)]\tLoss: 0.853873\n",
      "Train Epoch: 5 [4000/8544 (47%)]\tLoss: 0.717273\n",
      "Train Epoch: 5 [4400/8544 (51%)]\tLoss: 0.537793\n",
      "Train Epoch: 5 [4800/8544 (56%)]\tLoss: 0.665136\n",
      "Train Epoch: 5 [5200/8544 (61%)]\tLoss: 0.799813\n",
      "Train Epoch: 5 [5600/8544 (66%)]\tLoss: 0.600223\n",
      "Train Epoch: 5 [6000/8544 (70%)]\tLoss: 0.602745\n",
      "Train Epoch: 5 [6400/8544 (75%)]\tLoss: 1.345602\n",
      "Train Epoch: 5 [6800/8544 (80%)]\tLoss: 0.630542\n",
      "Train Epoch: 5 [7200/8544 (84%)]\tLoss: 0.896581\n",
      "Train Epoch: 5 [7600/8544 (89%)]\tLoss: 0.433086\n",
      "Train Epoch: 5 [8000/8544 (94%)]\tLoss: 0.687512\n",
      "Train Epoch: 5 [8400/8544 (98%)]\tLoss: 1.128587\n",
      "\n",
      "Test set: Average loss: 0.9229, Accuracy: 1576/2670 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/8544 (0%)]\tLoss: 1.042238\n",
      "Train Epoch: 6 [400/8544 (5%)]\tLoss: 0.756302\n",
      "Train Epoch: 6 [800/8544 (9%)]\tLoss: 0.811649\n",
      "Train Epoch: 6 [1200/8544 (14%)]\tLoss: 0.995649\n",
      "Train Epoch: 6 [1600/8544 (19%)]\tLoss: 1.004866\n",
      "Train Epoch: 6 [2000/8544 (23%)]\tLoss: 0.641654\n",
      "Train Epoch: 6 [2400/8544 (28%)]\tLoss: 0.684795\n",
      "Train Epoch: 6 [2800/8544 (33%)]\tLoss: 0.850233\n",
      "Train Epoch: 6 [3200/8544 (37%)]\tLoss: 0.981674\n",
      "Train Epoch: 6 [3600/8544 (42%)]\tLoss: 0.752848\n",
      "Train Epoch: 6 [4000/8544 (47%)]\tLoss: 0.814885\n",
      "Train Epoch: 6 [4400/8544 (51%)]\tLoss: 0.777650\n",
      "Train Epoch: 6 [4800/8544 (56%)]\tLoss: 0.728260\n",
      "Train Epoch: 6 [5200/8544 (61%)]\tLoss: 0.467981\n",
      "Train Epoch: 6 [5600/8544 (66%)]\tLoss: 0.906694\n",
      "Train Epoch: 6 [6000/8544 (70%)]\tLoss: 0.894271\n",
      "Train Epoch: 6 [6400/8544 (75%)]\tLoss: 0.834645\n",
      "Train Epoch: 6 [6800/8544 (80%)]\tLoss: 0.548054\n",
      "Train Epoch: 6 [7200/8544 (84%)]\tLoss: 0.984811\n",
      "Train Epoch: 6 [7600/8544 (89%)]\tLoss: 0.587014\n",
      "Train Epoch: 6 [8000/8544 (94%)]\tLoss: 0.778808\n",
      "Train Epoch: 6 [8400/8544 (98%)]\tLoss: 0.659268\n",
      "\n",
      "Test set: Average loss: 0.9197, Accuracy: 1572/2670 (59%)\n",
      "\n",
      "Train Epoch: 7 [0/8544 (0%)]\tLoss: 1.163075\n",
      "Train Epoch: 7 [400/8544 (5%)]\tLoss: 0.550177\n",
      "Train Epoch: 7 [800/8544 (9%)]\tLoss: 0.959931\n",
      "Train Epoch: 7 [1200/8544 (14%)]\tLoss: 0.599862\n",
      "Train Epoch: 7 [1600/8544 (19%)]\tLoss: 0.868810\n",
      "Train Epoch: 7 [2000/8544 (23%)]\tLoss: 1.273499\n",
      "Train Epoch: 7 [2400/8544 (28%)]\tLoss: 0.812065\n",
      "Train Epoch: 7 [2800/8544 (33%)]\tLoss: 1.101017\n",
      "Train Epoch: 7 [3200/8544 (37%)]\tLoss: 1.319516\n",
      "Train Epoch: 7 [3600/8544 (42%)]\tLoss: 1.075054\n",
      "Train Epoch: 7 [4000/8544 (47%)]\tLoss: 0.503154\n",
      "Train Epoch: 7 [4400/8544 (51%)]\tLoss: 1.503639\n",
      "Train Epoch: 7 [4800/8544 (56%)]\tLoss: 0.859353\n",
      "Train Epoch: 7 [5200/8544 (61%)]\tLoss: 0.852995\n",
      "Train Epoch: 7 [5600/8544 (66%)]\tLoss: 0.559986\n",
      "Train Epoch: 7 [6000/8544 (70%)]\tLoss: 0.808326\n",
      "Train Epoch: 7 [6400/8544 (75%)]\tLoss: 1.902199\n",
      "Train Epoch: 7 [6800/8544 (80%)]\tLoss: 1.012749\n",
      "Train Epoch: 7 [7200/8544 (84%)]\tLoss: 0.608304\n",
      "Train Epoch: 7 [7600/8544 (89%)]\tLoss: 0.508558\n",
      "Train Epoch: 7 [8000/8544 (94%)]\tLoss: 0.521732\n",
      "Train Epoch: 7 [8400/8544 (98%)]\tLoss: 0.661270\n",
      "\n",
      "Test set: Average loss: 0.9110, Accuracy: 1594/2670 (60%)\n",
      "\n",
      "Train Epoch: 8 [0/8544 (0%)]\tLoss: 1.049042\n",
      "Train Epoch: 8 [400/8544 (5%)]\tLoss: 0.634766\n",
      "Train Epoch: 8 [800/8544 (9%)]\tLoss: 0.940658\n",
      "Train Epoch: 8 [1200/8544 (14%)]\tLoss: 0.661135\n",
      "Train Epoch: 8 [1600/8544 (19%)]\tLoss: 1.206352\n",
      "Train Epoch: 8 [2000/8544 (23%)]\tLoss: 0.556653\n",
      "Train Epoch: 8 [2400/8544 (28%)]\tLoss: 0.641282\n",
      "Train Epoch: 8 [2800/8544 (33%)]\tLoss: 0.996569\n",
      "Train Epoch: 8 [3200/8544 (37%)]\tLoss: 0.823720\n",
      "Train Epoch: 8 [3600/8544 (42%)]\tLoss: 0.644734\n",
      "Train Epoch: 8 [4000/8544 (47%)]\tLoss: 0.570306\n",
      "Train Epoch: 8 [4400/8544 (51%)]\tLoss: 0.703275\n",
      "Train Epoch: 8 [4800/8544 (56%)]\tLoss: 1.196207\n",
      "Train Epoch: 8 [5200/8544 (61%)]\tLoss: 0.836519\n",
      "Train Epoch: 8 [5600/8544 (66%)]\tLoss: 0.809022\n",
      "Train Epoch: 8 [6000/8544 (70%)]\tLoss: 1.352352\n",
      "Train Epoch: 8 [6400/8544 (75%)]\tLoss: 0.813250\n",
      "Train Epoch: 8 [6800/8544 (80%)]\tLoss: 0.899026\n",
      "Train Epoch: 8 [7200/8544 (84%)]\tLoss: 0.334378\n",
      "Train Epoch: 8 [7600/8544 (89%)]\tLoss: 1.676682\n",
      "Train Epoch: 8 [8000/8544 (94%)]\tLoss: 0.851012\n",
      "Train Epoch: 8 [8400/8544 (98%)]\tLoss: 0.793957\n",
      "\n",
      "Test set: Average loss: 0.8943, Accuracy: 1635/2670 (61%)\n",
      "\n",
      "Train Epoch: 9 [0/8544 (0%)]\tLoss: 0.453168\n",
      "Train Epoch: 9 [400/8544 (5%)]\tLoss: 0.734810\n",
      "Train Epoch: 9 [800/8544 (9%)]\tLoss: 0.733314\n",
      "Train Epoch: 9 [1200/8544 (14%)]\tLoss: 1.020451\n",
      "Train Epoch: 9 [1600/8544 (19%)]\tLoss: 1.111142\n",
      "Train Epoch: 9 [2000/8544 (23%)]\tLoss: 0.670398\n",
      "Train Epoch: 9 [2400/8544 (28%)]\tLoss: 0.761908\n",
      "Train Epoch: 9 [2800/8544 (33%)]\tLoss: 0.955319\n",
      "Train Epoch: 9 [3200/8544 (37%)]\tLoss: 0.716455\n",
      "Train Epoch: 9 [3600/8544 (42%)]\tLoss: 0.795492\n",
      "Train Epoch: 9 [4000/8544 (47%)]\tLoss: 0.963554\n",
      "Train Epoch: 9 [4400/8544 (51%)]\tLoss: 0.614792\n",
      "Train Epoch: 9 [4800/8544 (56%)]\tLoss: 0.883836\n",
      "Train Epoch: 9 [5200/8544 (61%)]\tLoss: 0.631800\n",
      "Train Epoch: 9 [5600/8544 (66%)]\tLoss: 1.469521\n",
      "Train Epoch: 9 [6000/8544 (70%)]\tLoss: 0.979010\n",
      "Train Epoch: 9 [6400/8544 (75%)]\tLoss: 0.676478\n",
      "Train Epoch: 9 [6800/8544 (80%)]\tLoss: 0.556493\n",
      "Train Epoch: 9 [7200/8544 (84%)]\tLoss: 0.681320\n",
      "Train Epoch: 9 [7600/8544 (89%)]\tLoss: 0.674348\n",
      "Train Epoch: 9 [8000/8544 (94%)]\tLoss: 0.558810\n",
      "Train Epoch: 9 [8400/8544 (98%)]\tLoss: 0.620760\n",
      "\n",
      "Test set: Average loss: 0.9221, Accuracy: 1599/2670 (60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = embeddings.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = 4\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(embedding_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch, model, optimizer, verbose=True)\n",
    "    test(model, verbose=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
