{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get embedding vectors - each row is a job posting, each column is a feature\n",
    "embeddings = pd.read_csv('text_embeddings.csv', index_col=0)\n",
    "\n",
    "all_postings = pd.read_csv('processed_description.csv', index_col=0)\n",
    "\n",
    "text = all_postings['processed_description']\n",
    "salary_bins = all_postings['salary_bin']\n",
    "salary_ranges = all_postings['salary_range']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train, validation, and test set: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, salary_bins, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5913857677902622\n",
      "F1: 0.5878727474522593\n",
      "AUROC: 0.8310688877372037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, C = 1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('AUROC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6232209737827715\n",
      "F1: 0.6154045287037953\n",
      "ROC AUC: 0.8575517089215852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333333333333333\n",
      "F1: 0.6307232785335142\n",
      "ROC AUC: 0.8663795074185793\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb = xgb.XGBClassifier(objective='multi:softmax', num_class=5, max_depth=20, n_estimators=100)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_pred_proba = xgb.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601123595505618\n",
      "F1: 0.6018189006020477\n",
      "ROC AUC: 0.8058940526022109\n"
     ]
    }
   ],
   "source": [
    "#  feedforward\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,50) , max_iter=1000, learning_rate='adaptive')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_pred_proba, multi_class='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, hidden_layers=200):\n",
    "        super(NN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        for i in range(hidden_layers):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append((nn.ReLU()))\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "  \n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test loaders\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values).float()\n",
    "y_train_tensor = torch.tensor(y_train.values).float()\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).float()\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve\n",
    "from torch.nn import functional as F\n",
    "def train(epoch, model, optimizer, verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        # forward pass through the model\n",
    "        output = model(data)\n",
    "        # forward pass through the cross-entropy loss function\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        # backward pass through the cross-entropy loss function and the model\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            losses.append(loss.detach())\n",
    "            if verbose :\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return losses\n",
    "\n",
    "def test(model, verbose=False):\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # send data to device, where the \"device\" is either a GPU if it exists or a CPU\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability      \n",
    "                                                                       \n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        accuracy_list.append(accuracy) \n",
    "        if verbose :\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),\n",
    "                accuracy))\n",
    "    return test_loss\n",
    "        \n",
    "    \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/8544 (0%)]\tLoss: 1.386643\n",
      "Train Epoch: 0 [400/8544 (5%)]\tLoss: 1.186921\n",
      "Train Epoch: 0 [800/8544 (9%)]\tLoss: 1.323249\n",
      "Train Epoch: 0 [1200/8544 (14%)]\tLoss: 1.329290\n",
      "Train Epoch: 0 [1600/8544 (19%)]\tLoss: 1.249532\n",
      "Train Epoch: 0 [2000/8544 (23%)]\tLoss: 1.335153\n",
      "Train Epoch: 0 [2400/8544 (28%)]\tLoss: 1.066423\n",
      "Train Epoch: 0 [2800/8544 (33%)]\tLoss: 1.337828\n",
      "Train Epoch: 0 [3200/8544 (37%)]\tLoss: 1.282709\n",
      "Train Epoch: 0 [3600/8544 (42%)]\tLoss: 1.100019\n",
      "Train Epoch: 0 [4000/8544 (47%)]\tLoss: 1.119669\n",
      "Train Epoch: 0 [4400/8544 (51%)]\tLoss: 1.144823\n",
      "Train Epoch: 0 [4800/8544 (56%)]\tLoss: 1.103982\n",
      "Train Epoch: 0 [5200/8544 (61%)]\tLoss: 1.039426\n",
      "Train Epoch: 0 [5600/8544 (66%)]\tLoss: 1.817234\n",
      "Train Epoch: 0 [6000/8544 (70%)]\tLoss: 1.130325\n",
      "Train Epoch: 0 [6400/8544 (75%)]\tLoss: 1.272312\n",
      "Train Epoch: 0 [6800/8544 (80%)]\tLoss: 0.995580\n",
      "Train Epoch: 0 [7200/8544 (84%)]\tLoss: 1.092342\n",
      "Train Epoch: 0 [7600/8544 (89%)]\tLoss: 1.158856\n",
      "Train Epoch: 0 [8000/8544 (94%)]\tLoss: 0.842069\n",
      "Train Epoch: 0 [8400/8544 (98%)]\tLoss: 1.223090\n",
      "\n",
      "Test set: Average loss: 1.0354, Accuracy: 1362/2670 (51%)\n",
      "\n",
      "Train Epoch: 1 [0/8544 (0%)]\tLoss: 0.875003\n",
      "Train Epoch: 1 [400/8544 (5%)]\tLoss: 0.966447\n",
      "Train Epoch: 1 [800/8544 (9%)]\tLoss: 0.981333\n",
      "Train Epoch: 1 [1200/8544 (14%)]\tLoss: 1.426319\n",
      "Train Epoch: 1 [1600/8544 (19%)]\tLoss: 1.430047\n",
      "Train Epoch: 1 [2000/8544 (23%)]\tLoss: 1.230046\n",
      "Train Epoch: 1 [2400/8544 (28%)]\tLoss: 1.092703\n",
      "Train Epoch: 1 [2800/8544 (33%)]\tLoss: 1.024439\n",
      "Train Epoch: 1 [3200/8544 (37%)]\tLoss: 0.989651\n",
      "Train Epoch: 1 [3600/8544 (42%)]\tLoss: 1.227135\n",
      "Train Epoch: 1 [4000/8544 (47%)]\tLoss: 0.978931\n",
      "Train Epoch: 1 [4400/8544 (51%)]\tLoss: 0.854987\n",
      "Train Epoch: 1 [4800/8544 (56%)]\tLoss: 0.897001\n",
      "Train Epoch: 1 [5200/8544 (61%)]\tLoss: 0.711808\n",
      "Train Epoch: 1 [5600/8544 (66%)]\tLoss: 1.055013\n",
      "Train Epoch: 1 [6000/8544 (70%)]\tLoss: 0.945370\n",
      "Train Epoch: 1 [6400/8544 (75%)]\tLoss: 0.908506\n",
      "Train Epoch: 1 [6800/8544 (80%)]\tLoss: 1.385303\n",
      "Train Epoch: 1 [7200/8544 (84%)]\tLoss: 1.237026\n",
      "Train Epoch: 1 [7600/8544 (89%)]\tLoss: 1.034334\n",
      "Train Epoch: 1 [8000/8544 (94%)]\tLoss: 1.124870\n",
      "Train Epoch: 1 [8400/8544 (98%)]\tLoss: 0.624128\n",
      "\n",
      "Test set: Average loss: 0.9741, Accuracy: 1506/2670 (56%)\n",
      "\n",
      "Train Epoch: 2 [0/8544 (0%)]\tLoss: 0.864640\n",
      "Train Epoch: 2 [400/8544 (5%)]\tLoss: 1.212751\n",
      "Train Epoch: 2 [800/8544 (9%)]\tLoss: 0.754489\n",
      "Train Epoch: 2 [1200/8544 (14%)]\tLoss: 1.630049\n",
      "Train Epoch: 2 [1600/8544 (19%)]\tLoss: 0.998915\n",
      "Train Epoch: 2 [2000/8544 (23%)]\tLoss: 0.792284\n",
      "Train Epoch: 2 [2400/8544 (28%)]\tLoss: 0.856343\n",
      "Train Epoch: 2 [2800/8544 (33%)]\tLoss: 0.853464\n",
      "Train Epoch: 2 [3200/8544 (37%)]\tLoss: 0.964969\n",
      "Train Epoch: 2 [3600/8544 (42%)]\tLoss: 0.951854\n",
      "Train Epoch: 2 [4000/8544 (47%)]\tLoss: 1.054708\n",
      "Train Epoch: 2 [4400/8544 (51%)]\tLoss: 1.077016\n",
      "Train Epoch: 2 [4800/8544 (56%)]\tLoss: 0.925546\n",
      "Train Epoch: 2 [5200/8544 (61%)]\tLoss: 1.061302\n",
      "Train Epoch: 2 [5600/8544 (66%)]\tLoss: 0.803087\n",
      "Train Epoch: 2 [6000/8544 (70%)]\tLoss: 0.648031\n",
      "Train Epoch: 2 [6400/8544 (75%)]\tLoss: 1.024270\n",
      "Train Epoch: 2 [6800/8544 (80%)]\tLoss: 0.993203\n",
      "Train Epoch: 2 [7200/8544 (84%)]\tLoss: 0.762782\n",
      "Train Epoch: 2 [7600/8544 (89%)]\tLoss: 0.684252\n",
      "Train Epoch: 2 [8000/8544 (94%)]\tLoss: 0.746832\n",
      "Train Epoch: 2 [8400/8544 (98%)]\tLoss: 0.870572\n",
      "\n",
      "Test set: Average loss: 0.9675, Accuracy: 1503/2670 (56%)\n",
      "\n",
      "Train Epoch: 3 [0/8544 (0%)]\tLoss: 1.006740\n",
      "Train Epoch: 3 [400/8544 (5%)]\tLoss: 1.034333\n",
      "Train Epoch: 3 [800/8544 (9%)]\tLoss: 0.748445\n",
      "Train Epoch: 3 [1200/8544 (14%)]\tLoss: 1.444338\n",
      "Train Epoch: 3 [1600/8544 (19%)]\tLoss: 0.863190\n",
      "Train Epoch: 3 [2000/8544 (23%)]\tLoss: 1.446661\n",
      "Train Epoch: 3 [2400/8544 (28%)]\tLoss: 1.503615\n",
      "Train Epoch: 3 [2800/8544 (33%)]\tLoss: 0.679137\n",
      "Train Epoch: 3 [3200/8544 (37%)]\tLoss: 1.295517\n",
      "Train Epoch: 3 [3600/8544 (42%)]\tLoss: 1.111909\n",
      "Train Epoch: 3 [4000/8544 (47%)]\tLoss: 1.075587\n",
      "Train Epoch: 3 [4400/8544 (51%)]\tLoss: 1.274008\n",
      "Train Epoch: 3 [4800/8544 (56%)]\tLoss: 0.657265\n",
      "Train Epoch: 3 [5200/8544 (61%)]\tLoss: 0.887675\n",
      "Train Epoch: 3 [5600/8544 (66%)]\tLoss: 1.094974\n",
      "Train Epoch: 3 [6000/8544 (70%)]\tLoss: 0.784729\n",
      "Train Epoch: 3 [6400/8544 (75%)]\tLoss: 1.566620\n",
      "Train Epoch: 3 [6800/8544 (80%)]\tLoss: 0.764765\n",
      "Train Epoch: 3 [7200/8544 (84%)]\tLoss: 0.917505\n",
      "Train Epoch: 3 [7600/8544 (89%)]\tLoss: 0.804622\n",
      "Train Epoch: 3 [8000/8544 (94%)]\tLoss: 1.545696\n",
      "Train Epoch: 3 [8400/8544 (98%)]\tLoss: 1.170845\n",
      "\n",
      "Test set: Average loss: 0.9607, Accuracy: 1531/2670 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/8544 (0%)]\tLoss: 0.835558\n",
      "Train Epoch: 4 [400/8544 (5%)]\tLoss: 0.911356\n",
      "Train Epoch: 4 [800/8544 (9%)]\tLoss: 0.848733\n",
      "Train Epoch: 4 [1200/8544 (14%)]\tLoss: 0.840435\n",
      "Train Epoch: 4 [1600/8544 (19%)]\tLoss: 0.855518\n",
      "Train Epoch: 4 [2000/8544 (23%)]\tLoss: 0.635061\n",
      "Train Epoch: 4 [2400/8544 (28%)]\tLoss: 0.848301\n",
      "Train Epoch: 4 [2800/8544 (33%)]\tLoss: 1.146698\n",
      "Train Epoch: 4 [3200/8544 (37%)]\tLoss: 1.118432\n",
      "Train Epoch: 4 [3600/8544 (42%)]\tLoss: 0.742509\n",
      "Train Epoch: 4 [4000/8544 (47%)]\tLoss: 0.700819\n",
      "Train Epoch: 4 [4400/8544 (51%)]\tLoss: 1.041414\n",
      "Train Epoch: 4 [4800/8544 (56%)]\tLoss: 1.122179\n",
      "Train Epoch: 4 [5200/8544 (61%)]\tLoss: 1.279172\n",
      "Train Epoch: 4 [5600/8544 (66%)]\tLoss: 1.260887\n",
      "Train Epoch: 4 [6000/8544 (70%)]\tLoss: 0.611489\n",
      "Train Epoch: 4 [6400/8544 (75%)]\tLoss: 0.713994\n",
      "Train Epoch: 4 [6800/8544 (80%)]\tLoss: 1.194727\n",
      "Train Epoch: 4 [7200/8544 (84%)]\tLoss: 1.446226\n",
      "Train Epoch: 4 [7600/8544 (89%)]\tLoss: 1.149126\n",
      "Train Epoch: 4 [8000/8544 (94%)]\tLoss: 1.299789\n",
      "Train Epoch: 4 [8400/8544 (98%)]\tLoss: 0.829428\n",
      "\n",
      "Test set: Average loss: 0.9395, Accuracy: 1558/2670 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/8544 (0%)]\tLoss: 1.072289\n",
      "Train Epoch: 5 [400/8544 (5%)]\tLoss: 1.024485\n",
      "Train Epoch: 5 [800/8544 (9%)]\tLoss: 0.941220\n",
      "Train Epoch: 5 [1200/8544 (14%)]\tLoss: 1.166545\n",
      "Train Epoch: 5 [1600/8544 (19%)]\tLoss: 0.834966\n",
      "Train Epoch: 5 [2000/8544 (23%)]\tLoss: 0.699033\n",
      "Train Epoch: 5 [2400/8544 (28%)]\tLoss: 0.563751\n",
      "Train Epoch: 5 [2800/8544 (33%)]\tLoss: 0.609114\n",
      "Train Epoch: 5 [3200/8544 (37%)]\tLoss: 0.796804\n",
      "Train Epoch: 5 [3600/8544 (42%)]\tLoss: 0.850872\n",
      "Train Epoch: 5 [4000/8544 (47%)]\tLoss: 1.037143\n",
      "Train Epoch: 5 [4400/8544 (51%)]\tLoss: 0.558432\n",
      "Train Epoch: 5 [4800/8544 (56%)]\tLoss: 0.680379\n",
      "Train Epoch: 5 [5200/8544 (61%)]\tLoss: 0.774946\n",
      "Train Epoch: 5 [5600/8544 (66%)]\tLoss: 0.933662\n",
      "Train Epoch: 5 [6000/8544 (70%)]\tLoss: 0.973904\n",
      "Train Epoch: 5 [6400/8544 (75%)]\tLoss: 0.666442\n",
      "Train Epoch: 5 [6800/8544 (80%)]\tLoss: 0.966195\n",
      "Train Epoch: 5 [7200/8544 (84%)]\tLoss: 0.739364\n",
      "Train Epoch: 5 [7600/8544 (89%)]\tLoss: 0.588237\n",
      "Train Epoch: 5 [8000/8544 (94%)]\tLoss: 0.662591\n",
      "Train Epoch: 5 [8400/8544 (98%)]\tLoss: 1.043299\n",
      "\n",
      "Test set: Average loss: 0.9517, Accuracy: 1539/2670 (58%)\n",
      "\n",
      "Train Epoch: 6 [0/8544 (0%)]\tLoss: 0.721065\n",
      "Train Epoch: 6 [400/8544 (5%)]\tLoss: 1.369555\n",
      "Train Epoch: 6 [800/8544 (9%)]\tLoss: 0.748780\n",
      "Train Epoch: 6 [1200/8544 (14%)]\tLoss: 0.662607\n",
      "Train Epoch: 6 [1600/8544 (19%)]\tLoss: 1.021449\n",
      "Train Epoch: 6 [2000/8544 (23%)]\tLoss: 1.154657\n",
      "Train Epoch: 6 [2400/8544 (28%)]\tLoss: 1.239291\n",
      "Train Epoch: 6 [2800/8544 (33%)]\tLoss: 0.743541\n",
      "Train Epoch: 6 [3200/8544 (37%)]\tLoss: 0.838241\n",
      "Train Epoch: 6 [3600/8544 (42%)]\tLoss: 0.913896\n",
      "Train Epoch: 6 [4000/8544 (47%)]\tLoss: 0.629360\n",
      "Train Epoch: 6 [4400/8544 (51%)]\tLoss: 0.897610\n",
      "Train Epoch: 6 [4800/8544 (56%)]\tLoss: 1.526672\n",
      "Train Epoch: 6 [5200/8544 (61%)]\tLoss: 0.988647\n",
      "Train Epoch: 6 [5600/8544 (66%)]\tLoss: 1.137862\n",
      "Train Epoch: 6 [6000/8544 (70%)]\tLoss: 1.036677\n",
      "Train Epoch: 6 [6400/8544 (75%)]\tLoss: 1.045751\n",
      "Train Epoch: 6 [6800/8544 (80%)]\tLoss: 0.472460\n",
      "Train Epoch: 6 [7200/8544 (84%)]\tLoss: 1.194348\n",
      "Train Epoch: 6 [7600/8544 (89%)]\tLoss: 0.943190\n",
      "Train Epoch: 6 [8000/8544 (94%)]\tLoss: 0.611490\n",
      "Train Epoch: 6 [8400/8544 (98%)]\tLoss: 0.847834\n",
      "\n",
      "Test set: Average loss: 0.9354, Accuracy: 1574/2670 (59%)\n",
      "\n",
      "Train Epoch: 7 [0/8544 (0%)]\tLoss: 1.103724\n",
      "Train Epoch: 7 [400/8544 (5%)]\tLoss: 0.543864\n",
      "Train Epoch: 7 [800/8544 (9%)]\tLoss: 0.957844\n",
      "Train Epoch: 7 [1200/8544 (14%)]\tLoss: 0.922816\n",
      "Train Epoch: 7 [1600/8544 (19%)]\tLoss: 1.068725\n",
      "Train Epoch: 7 [2000/8544 (23%)]\tLoss: 0.729391\n",
      "Train Epoch: 7 [2400/8544 (28%)]\tLoss: 0.873705\n",
      "Train Epoch: 7 [2800/8544 (33%)]\tLoss: 0.674991\n",
      "Train Epoch: 7 [3200/8544 (37%)]\tLoss: 0.804705\n",
      "Train Epoch: 7 [3600/8544 (42%)]\tLoss: 0.714229\n",
      "Train Epoch: 7 [4000/8544 (47%)]\tLoss: 1.378679\n",
      "Train Epoch: 7 [4400/8544 (51%)]\tLoss: 0.732482\n",
      "Train Epoch: 7 [4800/8544 (56%)]\tLoss: 1.061803\n",
      "Train Epoch: 7 [5200/8544 (61%)]\tLoss: 1.204987\n",
      "Train Epoch: 7 [5600/8544 (66%)]\tLoss: 0.760448\n",
      "Train Epoch: 7 [6000/8544 (70%)]\tLoss: 0.592745\n",
      "Train Epoch: 7 [6400/8544 (75%)]\tLoss: 1.113945\n",
      "Train Epoch: 7 [6800/8544 (80%)]\tLoss: 0.840153\n",
      "Train Epoch: 7 [7200/8544 (84%)]\tLoss: 0.874604\n",
      "Train Epoch: 7 [7600/8544 (89%)]\tLoss: 0.456343\n",
      "Train Epoch: 7 [8000/8544 (94%)]\tLoss: 0.655561\n",
      "Train Epoch: 7 [8400/8544 (98%)]\tLoss: 0.757431\n",
      "\n",
      "Test set: Average loss: 0.9384, Accuracy: 1565/2670 (59%)\n",
      "\n",
      "Train Epoch: 8 [0/8544 (0%)]\tLoss: 0.847783\n",
      "Train Epoch: 8 [400/8544 (5%)]\tLoss: 0.615453\n",
      "Train Epoch: 8 [800/8544 (9%)]\tLoss: 0.454114\n",
      "Train Epoch: 8 [1200/8544 (14%)]\tLoss: 0.774203\n",
      "Train Epoch: 8 [1600/8544 (19%)]\tLoss: 1.020835\n",
      "Train Epoch: 8 [2000/8544 (23%)]\tLoss: 0.583615\n",
      "Train Epoch: 8 [2400/8544 (28%)]\tLoss: 0.512141\n",
      "Train Epoch: 8 [2800/8544 (33%)]\tLoss: 0.754002\n",
      "Train Epoch: 8 [3200/8544 (37%)]\tLoss: 0.561923\n",
      "Train Epoch: 8 [3600/8544 (42%)]\tLoss: 0.968151\n",
      "Train Epoch: 8 [4000/8544 (47%)]\tLoss: 0.711595\n",
      "Train Epoch: 8 [4400/8544 (51%)]\tLoss: 0.879585\n",
      "Train Epoch: 8 [4800/8544 (56%)]\tLoss: 0.816408\n",
      "Train Epoch: 8 [5200/8544 (61%)]\tLoss: 0.510947\n",
      "Train Epoch: 8 [5600/8544 (66%)]\tLoss: 0.651389\n",
      "Train Epoch: 8 [6000/8544 (70%)]\tLoss: 0.860692\n",
      "Train Epoch: 8 [6400/8544 (75%)]\tLoss: 1.034738\n",
      "Train Epoch: 8 [6800/8544 (80%)]\tLoss: 0.734878\n",
      "Train Epoch: 8 [7200/8544 (84%)]\tLoss: 0.789014\n",
      "Train Epoch: 8 [7600/8544 (89%)]\tLoss: 0.796551\n",
      "Train Epoch: 8 [8000/8544 (94%)]\tLoss: 0.517257\n",
      "Train Epoch: 8 [8400/8544 (98%)]\tLoss: 0.696640\n",
      "\n",
      "Test set: Average loss: 0.9595, Accuracy: 1528/2670 (57%)\n",
      "\n",
      "Train Epoch: 9 [0/8544 (0%)]\tLoss: 0.955061\n",
      "Train Epoch: 9 [400/8544 (5%)]\tLoss: 0.994047\n",
      "Train Epoch: 9 [800/8544 (9%)]\tLoss: 1.213001\n",
      "Train Epoch: 9 [1200/8544 (14%)]\tLoss: 1.166693\n",
      "Train Epoch: 9 [1600/8544 (19%)]\tLoss: 0.860793\n",
      "Train Epoch: 9 [2000/8544 (23%)]\tLoss: 0.826614\n",
      "Train Epoch: 9 [2400/8544 (28%)]\tLoss: 0.741973\n",
      "Train Epoch: 9 [2800/8544 (33%)]\tLoss: 1.283752\n",
      "Train Epoch: 9 [3200/8544 (37%)]\tLoss: 0.699729\n",
      "Train Epoch: 9 [3600/8544 (42%)]\tLoss: 1.418495\n",
      "Train Epoch: 9 [4000/8544 (47%)]\tLoss: 1.055112\n",
      "Train Epoch: 9 [4400/8544 (51%)]\tLoss: 0.799373\n",
      "Train Epoch: 9 [4800/8544 (56%)]\tLoss: 0.660651\n",
      "Train Epoch: 9 [5200/8544 (61%)]\tLoss: 1.124138\n",
      "Train Epoch: 9 [5600/8544 (66%)]\tLoss: 0.725821\n",
      "Train Epoch: 9 [6000/8544 (70%)]\tLoss: 0.815406\n",
      "Train Epoch: 9 [6400/8544 (75%)]\tLoss: 0.937892\n",
      "Train Epoch: 9 [6800/8544 (80%)]\tLoss: 0.914974\n",
      "Train Epoch: 9 [7200/8544 (84%)]\tLoss: 0.673019\n",
      "Train Epoch: 9 [7600/8544 (89%)]\tLoss: 0.520016\n",
      "Train Epoch: 9 [8000/8544 (94%)]\tLoss: 0.913834\n",
      "Train Epoch: 9 [8400/8544 (98%)]\tLoss: 1.120115\n",
      "\n",
      "Test set: Average loss: 0.9441, Accuracy: 1544/2670 (58%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "hidden_dim = 50\n",
    "\n",
    "hidden_layers = 4\n",
    "input_dim = embeddings.shape[1]\n",
    "output_dim = 4\n",
    "model = NN(input_dim, hidden_dim, output_dim, hidden_layers)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)    \n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch, model, optimizer, verbose=True)\n",
    "    test(model, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_test_tensor.to(device)).argmax(dim=1).cpu().numpy()\n",
    "f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "\n",
    "\n",
    "\n",
    "print('Dense Neural Network F1-Score: ', f1_score)\n",
    "print('Dense Neural Network ROC AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model (RNN Variant)\n",
    "Long Short-Term Memory layer in a neural netowrk model perform well in tasks involve learning long-term dependencies in sequential data, addressing limitation of a traditional RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/8544 (0%)]\tLoss: 1.397965\n",
      "Train Epoch: 0 [400/8544 (5%)]\tLoss: 1.185628\n",
      "Train Epoch: 0 [800/8544 (9%)]\tLoss: 1.473814\n",
      "Train Epoch: 0 [1200/8544 (14%)]\tLoss: 1.259106\n",
      "Train Epoch: 0 [1600/8544 (19%)]\tLoss: 1.146459\n",
      "Train Epoch: 0 [2000/8544 (23%)]\tLoss: 1.104923\n",
      "Train Epoch: 0 [2400/8544 (28%)]\tLoss: 1.712861\n",
      "Train Epoch: 0 [2800/8544 (33%)]\tLoss: 1.190661\n",
      "Train Epoch: 0 [3200/8544 (37%)]\tLoss: 1.285010\n",
      "Train Epoch: 0 [3600/8544 (42%)]\tLoss: 0.930112\n",
      "Train Epoch: 0 [4000/8544 (47%)]\tLoss: 0.952230\n",
      "Train Epoch: 0 [4400/8544 (51%)]\tLoss: 1.140800\n",
      "Train Epoch: 0 [4800/8544 (56%)]\tLoss: 1.183375\n",
      "Train Epoch: 0 [5200/8544 (61%)]\tLoss: 1.260535\n",
      "Train Epoch: 0 [5600/8544 (66%)]\tLoss: 0.865739\n",
      "Train Epoch: 0 [6000/8544 (70%)]\tLoss: 1.155329\n",
      "Train Epoch: 0 [6400/8544 (75%)]\tLoss: 0.924492\n",
      "Train Epoch: 0 [6800/8544 (80%)]\tLoss: 0.876513\n",
      "Train Epoch: 0 [7200/8544 (84%)]\tLoss: 0.921574\n",
      "Train Epoch: 0 [7600/8544 (89%)]\tLoss: 0.947122\n",
      "Train Epoch: 0 [8000/8544 (94%)]\tLoss: 0.834485\n",
      "Train Epoch: 0 [8400/8544 (98%)]\tLoss: 0.785197\n",
      "\n",
      "Test set: Average loss: 0.9955, Accuracy: 1440/2670 (54%)\n",
      "\n",
      "Train Epoch: 1 [0/8544 (0%)]\tLoss: 0.943282\n",
      "Train Epoch: 1 [400/8544 (5%)]\tLoss: 1.263435\n",
      "Train Epoch: 1 [800/8544 (9%)]\tLoss: 0.951144\n",
      "Train Epoch: 1 [1200/8544 (14%)]\tLoss: 1.180210\n",
      "Train Epoch: 1 [1600/8544 (19%)]\tLoss: 1.017416\n",
      "Train Epoch: 1 [2000/8544 (23%)]\tLoss: 0.871858\n",
      "Train Epoch: 1 [2400/8544 (28%)]\tLoss: 0.926790\n",
      "Train Epoch: 1 [2800/8544 (33%)]\tLoss: 0.824620\n",
      "Train Epoch: 1 [3200/8544 (37%)]\tLoss: 0.885450\n",
      "Train Epoch: 1 [3600/8544 (42%)]\tLoss: 0.685222\n",
      "Train Epoch: 1 [4000/8544 (47%)]\tLoss: 1.143341\n",
      "Train Epoch: 1 [4400/8544 (51%)]\tLoss: 1.107391\n",
      "Train Epoch: 1 [4800/8544 (56%)]\tLoss: 0.779700\n",
      "Train Epoch: 1 [5200/8544 (61%)]\tLoss: 1.031975\n",
      "Train Epoch: 1 [5600/8544 (66%)]\tLoss: 1.079107\n",
      "Train Epoch: 1 [6000/8544 (70%)]\tLoss: 0.962105\n",
      "Train Epoch: 1 [6400/8544 (75%)]\tLoss: 0.477778\n",
      "Train Epoch: 1 [6800/8544 (80%)]\tLoss: 1.011314\n",
      "Train Epoch: 1 [7200/8544 (84%)]\tLoss: 0.746172\n",
      "Train Epoch: 1 [7600/8544 (89%)]\tLoss: 0.911179\n",
      "Train Epoch: 1 [8000/8544 (94%)]\tLoss: 1.024380\n",
      "Train Epoch: 1 [8400/8544 (98%)]\tLoss: 0.804222\n",
      "\n",
      "Test set: Average loss: 0.9818, Accuracy: 1462/2670 (55%)\n",
      "\n",
      "Train Epoch: 2 [0/8544 (0%)]\tLoss: 0.950154\n",
      "Train Epoch: 2 [400/8544 (5%)]\tLoss: 0.942649\n",
      "Train Epoch: 2 [800/8544 (9%)]\tLoss: 0.688732\n",
      "Train Epoch: 2 [1200/8544 (14%)]\tLoss: 1.111122\n",
      "Train Epoch: 2 [1600/8544 (19%)]\tLoss: 1.372560\n",
      "Train Epoch: 2 [2000/8544 (23%)]\tLoss: 1.141802\n",
      "Train Epoch: 2 [2400/8544 (28%)]\tLoss: 0.935561\n",
      "Train Epoch: 2 [2800/8544 (33%)]\tLoss: 1.075881\n",
      "Train Epoch: 2 [3200/8544 (37%)]\tLoss: 0.956024\n",
      "Train Epoch: 2 [3600/8544 (42%)]\tLoss: 0.879224\n",
      "Train Epoch: 2 [4000/8544 (47%)]\tLoss: 0.720215\n",
      "Train Epoch: 2 [4400/8544 (51%)]\tLoss: 0.755004\n",
      "Train Epoch: 2 [4800/8544 (56%)]\tLoss: 1.406036\n",
      "Train Epoch: 2 [5200/8544 (61%)]\tLoss: 0.995485\n",
      "Train Epoch: 2 [5600/8544 (66%)]\tLoss: 1.862855\n",
      "Train Epoch: 2 [6000/8544 (70%)]\tLoss: 0.845460\n",
      "Train Epoch: 2 [6400/8544 (75%)]\tLoss: 1.330600\n",
      "Train Epoch: 2 [6800/8544 (80%)]\tLoss: 1.046865\n",
      "Train Epoch: 2 [7200/8544 (84%)]\tLoss: 0.766968\n",
      "Train Epoch: 2 [7600/8544 (89%)]\tLoss: 1.223513\n",
      "Train Epoch: 2 [8000/8544 (94%)]\tLoss: 1.041919\n",
      "Train Epoch: 2 [8400/8544 (98%)]\tLoss: 1.584833\n",
      "\n",
      "Test set: Average loss: 0.9644, Accuracy: 1496/2670 (56%)\n",
      "\n",
      "Train Epoch: 3 [0/8544 (0%)]\tLoss: 1.226696\n",
      "Train Epoch: 3 [400/8544 (5%)]\tLoss: 0.754877\n",
      "Train Epoch: 3 [800/8544 (9%)]\tLoss: 0.949663\n",
      "Train Epoch: 3 [1200/8544 (14%)]\tLoss: 0.955763\n",
      "Train Epoch: 3 [1600/8544 (19%)]\tLoss: 1.056026\n",
      "Train Epoch: 3 [2000/8544 (23%)]\tLoss: 0.941049\n",
      "Train Epoch: 3 [2400/8544 (28%)]\tLoss: 0.767858\n",
      "Train Epoch: 3 [2800/8544 (33%)]\tLoss: 1.136174\n",
      "Train Epoch: 3 [3200/8544 (37%)]\tLoss: 0.748837\n",
      "Train Epoch: 3 [3600/8544 (42%)]\tLoss: 0.679962\n",
      "Train Epoch: 3 [4000/8544 (47%)]\tLoss: 0.950662\n",
      "Train Epoch: 3 [4400/8544 (51%)]\tLoss: 1.377399\n",
      "Train Epoch: 3 [4800/8544 (56%)]\tLoss: 1.252734\n",
      "Train Epoch: 3 [5200/8544 (61%)]\tLoss: 1.040970\n",
      "Train Epoch: 3 [5600/8544 (66%)]\tLoss: 1.263329\n",
      "Train Epoch: 3 [6000/8544 (70%)]\tLoss: 0.932461\n",
      "Train Epoch: 3 [6400/8544 (75%)]\tLoss: 0.958249\n",
      "Train Epoch: 3 [6800/8544 (80%)]\tLoss: 1.262263\n",
      "Train Epoch: 3 [7200/8544 (84%)]\tLoss: 1.378140\n",
      "Train Epoch: 3 [7600/8544 (89%)]\tLoss: 0.861892\n",
      "Train Epoch: 3 [8000/8544 (94%)]\tLoss: 1.161284\n",
      "Train Epoch: 3 [8400/8544 (98%)]\tLoss: 1.068746\n",
      "\n",
      "Test set: Average loss: 0.9340, Accuracy: 1565/2670 (59%)\n",
      "\n",
      "Train Epoch: 4 [0/8544 (0%)]\tLoss: 0.982314\n",
      "Train Epoch: 4 [400/8544 (5%)]\tLoss: 0.823279\n",
      "Train Epoch: 4 [800/8544 (9%)]\tLoss: 0.923195\n",
      "Train Epoch: 4 [1200/8544 (14%)]\tLoss: 0.730069\n",
      "Train Epoch: 4 [1600/8544 (19%)]\tLoss: 1.733356\n",
      "Train Epoch: 4 [2000/8544 (23%)]\tLoss: 1.028366\n",
      "Train Epoch: 4 [2400/8544 (28%)]\tLoss: 1.120293\n",
      "Train Epoch: 4 [2800/8544 (33%)]\tLoss: 1.423225\n",
      "Train Epoch: 4 [3200/8544 (37%)]\tLoss: 1.404117\n",
      "Train Epoch: 4 [3600/8544 (42%)]\tLoss: 1.334797\n",
      "Train Epoch: 4 [4000/8544 (47%)]\tLoss: 1.096625\n",
      "Train Epoch: 4 [4400/8544 (51%)]\tLoss: 0.736221\n",
      "Train Epoch: 4 [4800/8544 (56%)]\tLoss: 1.337896\n",
      "Train Epoch: 4 [5200/8544 (61%)]\tLoss: 1.307691\n",
      "Train Epoch: 4 [5600/8544 (66%)]\tLoss: 0.912620\n",
      "Train Epoch: 4 [6000/8544 (70%)]\tLoss: 0.687445\n",
      "Train Epoch: 4 [6400/8544 (75%)]\tLoss: 0.656376\n",
      "Train Epoch: 4 [6800/8544 (80%)]\tLoss: 0.567759\n",
      "Train Epoch: 4 [7200/8544 (84%)]\tLoss: 0.714795\n",
      "Train Epoch: 4 [7600/8544 (89%)]\tLoss: 1.128220\n",
      "Train Epoch: 4 [8000/8544 (94%)]\tLoss: 1.371016\n",
      "Train Epoch: 4 [8400/8544 (98%)]\tLoss: 1.579138\n",
      "\n",
      "Test set: Average loss: 0.9288, Accuracy: 1561/2670 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/8544 (0%)]\tLoss: 1.021015\n",
      "Train Epoch: 5 [400/8544 (5%)]\tLoss: 0.569884\n",
      "Train Epoch: 5 [800/8544 (9%)]\tLoss: 0.846994\n",
      "Train Epoch: 5 [1200/8544 (14%)]\tLoss: 0.397150\n",
      "Train Epoch: 5 [1600/8544 (19%)]\tLoss: 1.123293\n",
      "Train Epoch: 5 [2000/8544 (23%)]\tLoss: 1.061291\n",
      "Train Epoch: 5 [2400/8544 (28%)]\tLoss: 0.664288\n",
      "Train Epoch: 5 [2800/8544 (33%)]\tLoss: 1.015362\n",
      "Train Epoch: 5 [3200/8544 (37%)]\tLoss: 1.007063\n",
      "Train Epoch: 5 [3600/8544 (42%)]\tLoss: 0.669741\n",
      "Train Epoch: 5 [4000/8544 (47%)]\tLoss: 1.194010\n",
      "Train Epoch: 5 [4400/8544 (51%)]\tLoss: 0.821656\n",
      "Train Epoch: 5 [4800/8544 (56%)]\tLoss: 0.761754\n",
      "Train Epoch: 5 [5200/8544 (61%)]\tLoss: 0.904441\n",
      "Train Epoch: 5 [5600/8544 (66%)]\tLoss: 1.132329\n",
      "Train Epoch: 5 [6000/8544 (70%)]\tLoss: 0.672580\n",
      "Train Epoch: 5 [6400/8544 (75%)]\tLoss: 1.096515\n",
      "Train Epoch: 5 [6800/8544 (80%)]\tLoss: 0.823062\n",
      "Train Epoch: 5 [7200/8544 (84%)]\tLoss: 0.821859\n",
      "Train Epoch: 5 [7600/8544 (89%)]\tLoss: 0.622161\n",
      "Train Epoch: 5 [8000/8544 (94%)]\tLoss: 0.757244\n",
      "Train Epoch: 5 [8400/8544 (98%)]\tLoss: 1.243983\n",
      "\n",
      "Test set: Average loss: 0.9223, Accuracy: 1587/2670 (59%)\n",
      "\n",
      "Train Epoch: 6 [0/8544 (0%)]\tLoss: 0.627233\n",
      "Train Epoch: 6 [400/8544 (5%)]\tLoss: 0.625724\n",
      "Train Epoch: 6 [800/8544 (9%)]\tLoss: 0.621766\n",
      "Train Epoch: 6 [1200/8544 (14%)]\tLoss: 0.531011\n",
      "Train Epoch: 6 [1600/8544 (19%)]\tLoss: 0.741009\n",
      "Train Epoch: 6 [2000/8544 (23%)]\tLoss: 0.805047\n",
      "Train Epoch: 6 [2400/8544 (28%)]\tLoss: 0.713865\n",
      "Train Epoch: 6 [2800/8544 (33%)]\tLoss: 0.623569\n",
      "Train Epoch: 6 [3200/8544 (37%)]\tLoss: 0.921782\n",
      "Train Epoch: 6 [3600/8544 (42%)]\tLoss: 0.549572\n",
      "Train Epoch: 6 [4000/8544 (47%)]\tLoss: 1.091244\n",
      "Train Epoch: 6 [4400/8544 (51%)]\tLoss: 0.938520\n",
      "Train Epoch: 6 [4800/8544 (56%)]\tLoss: 0.574783\n",
      "Train Epoch: 6 [5200/8544 (61%)]\tLoss: 0.953162\n",
      "Train Epoch: 6 [5600/8544 (66%)]\tLoss: 1.391312\n",
      "Train Epoch: 6 [6000/8544 (70%)]\tLoss: 0.607942\n",
      "Train Epoch: 6 [6400/8544 (75%)]\tLoss: 0.771203\n",
      "Train Epoch: 6 [6800/8544 (80%)]\tLoss: 0.789800\n",
      "Train Epoch: 6 [7200/8544 (84%)]\tLoss: 0.769269\n",
      "Train Epoch: 6 [7600/8544 (89%)]\tLoss: 0.834648\n",
      "Train Epoch: 6 [8000/8544 (94%)]\tLoss: 0.536551\n",
      "Train Epoch: 6 [8400/8544 (98%)]\tLoss: 0.605789\n",
      "\n",
      "Test set: Average loss: 0.9108, Accuracy: 1600/2670 (60%)\n",
      "\n",
      "Train Epoch: 7 [0/8544 (0%)]\tLoss: 1.032004\n",
      "Train Epoch: 7 [400/8544 (5%)]\tLoss: 0.591551\n",
      "Train Epoch: 7 [800/8544 (9%)]\tLoss: 0.734008\n",
      "Train Epoch: 7 [1200/8544 (14%)]\tLoss: 0.803606\n",
      "Train Epoch: 7 [1600/8544 (19%)]\tLoss: 0.686037\n",
      "Train Epoch: 7 [2000/8544 (23%)]\tLoss: 0.661228\n",
      "Train Epoch: 7 [2400/8544 (28%)]\tLoss: 0.895607\n",
      "Train Epoch: 7 [2800/8544 (33%)]\tLoss: 0.619816\n",
      "Train Epoch: 7 [3200/8544 (37%)]\tLoss: 0.658701\n",
      "Train Epoch: 7 [3600/8544 (42%)]\tLoss: 0.954676\n",
      "Train Epoch: 7 [4000/8544 (47%)]\tLoss: 0.752842\n",
      "Train Epoch: 7 [4400/8544 (51%)]\tLoss: 1.342406\n",
      "Train Epoch: 7 [4800/8544 (56%)]\tLoss: 0.783683\n",
      "Train Epoch: 7 [5200/8544 (61%)]\tLoss: 0.688283\n",
      "Train Epoch: 7 [5600/8544 (66%)]\tLoss: 0.842892\n",
      "Train Epoch: 7 [6000/8544 (70%)]\tLoss: 0.699822\n",
      "Train Epoch: 7 [6400/8544 (75%)]\tLoss: 1.158656\n",
      "Train Epoch: 7 [6800/8544 (80%)]\tLoss: 0.765581\n",
      "Train Epoch: 7 [7200/8544 (84%)]\tLoss: 0.801566\n",
      "Train Epoch: 7 [7600/8544 (89%)]\tLoss: 1.282148\n",
      "Train Epoch: 7 [8000/8544 (94%)]\tLoss: 0.844783\n",
      "Train Epoch: 7 [8400/8544 (98%)]\tLoss: 1.324668\n",
      "\n",
      "Test set: Average loss: 0.9419, Accuracy: 1533/2670 (57%)\n",
      "\n",
      "Train Epoch: 8 [0/8544 (0%)]\tLoss: 1.041359\n",
      "Train Epoch: 8 [400/8544 (5%)]\tLoss: 0.713241\n",
      "Train Epoch: 8 [800/8544 (9%)]\tLoss: 0.918200\n",
      "Train Epoch: 8 [1200/8544 (14%)]\tLoss: 0.761218\n",
      "Train Epoch: 8 [1600/8544 (19%)]\tLoss: 0.820458\n",
      "Train Epoch: 8 [2000/8544 (23%)]\tLoss: 0.440971\n",
      "Train Epoch: 8 [2400/8544 (28%)]\tLoss: 0.745669\n",
      "Train Epoch: 8 [2800/8544 (33%)]\tLoss: 0.621047\n",
      "Train Epoch: 8 [3200/8544 (37%)]\tLoss: 0.841971\n",
      "Train Epoch: 8 [3600/8544 (42%)]\tLoss: 0.875749\n",
      "Train Epoch: 8 [4000/8544 (47%)]\tLoss: 0.983346\n",
      "Train Epoch: 8 [4400/8544 (51%)]\tLoss: 1.274106\n",
      "Train Epoch: 8 [4800/8544 (56%)]\tLoss: 0.684525\n",
      "Train Epoch: 8 [5200/8544 (61%)]\tLoss: 0.564996\n",
      "Train Epoch: 8 [5600/8544 (66%)]\tLoss: 1.491530\n",
      "Train Epoch: 8 [6000/8544 (70%)]\tLoss: 1.767737\n",
      "Train Epoch: 8 [6400/8544 (75%)]\tLoss: 0.865213\n",
      "Train Epoch: 8 [6800/8544 (80%)]\tLoss: 0.664501\n",
      "Train Epoch: 8 [7200/8544 (84%)]\tLoss: 0.960644\n",
      "Train Epoch: 8 [7600/8544 (89%)]\tLoss: 0.765337\n",
      "Train Epoch: 8 [8000/8544 (94%)]\tLoss: 0.607611\n",
      "Train Epoch: 8 [8400/8544 (98%)]\tLoss: 0.560412\n",
      "\n",
      "Test set: Average loss: 0.9143, Accuracy: 1608/2670 (60%)\n",
      "\n",
      "Train Epoch: 9 [0/8544 (0%)]\tLoss: 0.833965\n",
      "Train Epoch: 9 [400/8544 (5%)]\tLoss: 0.566426\n",
      "Train Epoch: 9 [800/8544 (9%)]\tLoss: 0.763827\n",
      "Train Epoch: 9 [1200/8544 (14%)]\tLoss: 0.629408\n",
      "Train Epoch: 9 [1600/8544 (19%)]\tLoss: 0.634593\n",
      "Train Epoch: 9 [2000/8544 (23%)]\tLoss: 0.528005\n",
      "Train Epoch: 9 [2400/8544 (28%)]\tLoss: 0.452593\n",
      "Train Epoch: 9 [2800/8544 (33%)]\tLoss: 0.508537\n",
      "Train Epoch: 9 [3200/8544 (37%)]\tLoss: 0.763534\n",
      "Train Epoch: 9 [3600/8544 (42%)]\tLoss: 0.586345\n",
      "Train Epoch: 9 [4000/8544 (47%)]\tLoss: 0.831192\n",
      "Train Epoch: 9 [4400/8544 (51%)]\tLoss: 1.026468\n",
      "Train Epoch: 9 [4800/8544 (56%)]\tLoss: 0.923634\n",
      "Train Epoch: 9 [5200/8544 (61%)]\tLoss: 0.690455\n",
      "Train Epoch: 9 [5600/8544 (66%)]\tLoss: 0.800592\n",
      "Train Epoch: 9 [6000/8544 (70%)]\tLoss: 0.344825\n",
      "Train Epoch: 9 [6400/8544 (75%)]\tLoss: 1.116022\n",
      "Train Epoch: 9 [6800/8544 (80%)]\tLoss: 1.454979\n",
      "Train Epoch: 9 [7200/8544 (84%)]\tLoss: 0.763361\n",
      "Train Epoch: 9 [7600/8544 (89%)]\tLoss: 0.682980\n",
      "Train Epoch: 9 [8000/8544 (94%)]\tLoss: 0.797301\n",
      "Train Epoch: 9 [8400/8544 (98%)]\tLoss: 0.954441\n",
      "\n",
      "Test set: Average loss: 0.9060, Accuracy: 1608/2670 (60%)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_test_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model(X_test_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 18\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_proba, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM F1-Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, f1_score)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "embedding_dim = embeddings.shape[1]\n",
    "hidden_dim = 100\n",
    "output_dim = 4\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTMModel(embedding_dim, hidden_dim, num_layers, output_dim)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train(epoch, model, optimizer, verbose=True)\n",
    "    test(model, verbose=True)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_test_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      2\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model(X_test_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m----> 3\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, y_pred_proba, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM F1-Score: \u001b[39m\u001b[38;5;124m'\u001b[39m, f1_score)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "y_pred = model(X_test_tensor.to(device)).argmax(dim=1).cpu()\n",
    "y_pred_proba = model(X_test_tensor.to(device)).argmax(dim=1).cpu().detach()\n",
    "f1_score = f1_score(y_test, y_pred, average='weighted')\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print('LSTM F1-Score: ', f1_score)\n",
    "print('LSTM ROC AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
